# Properties file defining options for the MetaCatServlet.java servlet
#
# Matt Jones, Dan Higgins, Jivka Bojilova
# '$Id$'
#

######## Configuration utility section  ################

configutil.propertiesConfigured=false
configutil.authConfigured=false
configutil.skinsConfigured=true
configutil.databaseConfigured=false
configutil.solrserverConfigured=false
configutil.dataoneConfigured=false
configutil.ezidConfigured=bypassed
configutil.quotaConfigured=bypassed

#The property of configutil.upgrade.status depends on other status (database, java et al). 
#If all of them are success, the property of configutil.upgrade will be successs; otherwise failure.
configutil.upgrade.status=
configutil.upgrade.database.status=
configutil.upgrade.java.status=
configutil.upgrade.solr.status=

############### Server Values #################

server.name=localhost
server.httpPort=80
server.httpSSLPort=443
server.internalName=localhost
server.internalPort=80

############### Application Values ############

## one of the few places where we use ANT tokens
application.metacatVersion=2.19.1
application.metacatReleaseInfo=-1
application.readOnlyMode=false

application.deployDir=
## This is autodiscovered and populated by the config utility
application.context=
application.default-style=metacatui
application.knbSiteURL=http://knb.ecoinformatics.org
application.backupDir=
application.datafilepath=/var/metacat/data
application.inlinedatafilepath=/var/metacat/inline-data
application.documentfilepath=/var/metacat/documents
application.expandedArchivePath=/var/metacat/expanded-archives
application.tempDir=/var/metacat/temporary
# the location of cgi scripts relative to the metacat context directory
application.cgiDir=/cgi-bin
#used for writing debug info into a anouther out file
application.writeDebugToFile=true
#output file name where debug info will written
# TODO SCW: these should be using the temp-dir property for their paths (change in code)
application.debugOutputFile=/tmp/metacat.debug
#delimitered text output file name where debug info will be written
application.delimiteredOutputFile=/tmp/metacat.debug.delimitered

############### Database Values ###############

database.connectionURI=jdbc:postgresql://localhost/metacat
database.user=
database.password=
database.type=
database.driver=
database.adapter=
database.scriptsuffix.postgres=postgres.sql
database.scriptsuffix.oracle=oracle.sql
database.scriptsuffix.sqlserver=sqlserver.sql
database.upgradeVersion.0.0.0=xmltables,loaddtdschema
database.upgradeVersion.1.2.0=upgrade-db-to-1.2
database.upgradeVersion.1.3.0=upgrade-db-to-1.3
database.upgradeVersion.1.4.0=upgrade-db-to-1.4
database.upgradeVersion.1.5.0=upgrade-db-to-1.5
database.upgradeVersion.1.6.0=upgrade-db-to-1.6
database.upgradeVersion.1.7.0=upgrade-db-to-1.7
database.upgradeVersion.1.8.0=upgrade-db-to-1.8
database.upgradeVersion.1.9.0=upgrade-db-to-1.9
database.upgradeVersion.1.9.1=upgrade-db-to-1.9.1
database.upgradeVersion.1.9.2=upgrade-db-to-1.9.2
database.upgradeVersion.1.9.3=upgrade-db-to-1.9.3
database.upgradeVersion.1.9.4=upgrade-db-to-1.9.4
database.upgradeVersion.1.9.5=upgrade-db-to-1.9.5
database.upgradeVersion.2.0.0=upgrade-db-to-2.0.0
database.upgradeVersion.2.0.1=upgrade-db-to-2.0.1
database.upgradeVersion.2.0.2=upgrade-db-to-2.0.2
database.upgradeVersion.2.0.3=upgrade-db-to-2.0.3
database.upgradeVersion.2.0.4=upgrade-db-to-2.0.4
database.upgradeVersion.2.0.5=upgrade-db-to-2.0.5
database.upgradeVersion.2.0.6=upgrade-db-to-2.0.6
database.upgradeVersion.2.0.7=upgrade-db-to-2.0.7
database.upgradeVersion.2.0.8=upgrade-db-to-2.0.8
database.upgradeVersion.2.1.0=upgrade-db-to-2.1.0
database.upgradeVersion.2.1.1=upgrade-db-to-2.1.1
database.upgradeVersion.2.2.0=upgrade-db-to-2.2.0
database.upgradeVersion.2.2.1=upgrade-db-to-2.2.1
database.upgradeVersion.2.3.0=upgrade-db-to-2.3.0
database.upgradeVersion.2.3.1=upgrade-db-to-2.3.1
database.upgradeVersion.2.4.0=upgrade-db-to-2.4.0
database.upgradeVersion.2.4.1=upgrade-db-to-2.4.1
database.upgradeVersion.2.4.2=upgrade-db-to-2.4.2
database.upgradeVersion.2.4.3=upgrade-db-to-2.4.3
database.upgradeVersion.2.5.0=upgrade-db-to-2.5.0
database.upgradeVersion.2.5.1=upgrade-db-to-2.5.1
database.upgradeVersion.2.6.0=upgrade-db-to-2.6.0
database.upgradeVersion.2.7.0=upgrade-db-to-2.7.0
database.upgradeVersion.2.7.1=upgrade-db-to-2.7.1
database.upgradeVersion.2.7.2=upgrade-db-to-2.7.2
database.upgradeVersion.2.8.0=upgrade-db-to-2.8.0
database.upgradeVersion.2.8.1=upgrade-db-to-2.8.1
database.upgradeVersion.2.8.2=upgrade-db-to-2.8.2
database.upgradeVersion.2.8.3=upgrade-db-to-2.8.3
database.upgradeVersion.2.8.4=upgrade-db-to-2.8.4
database.upgradeVersion.2.8.5=upgrade-db-to-2.8.5
database.upgradeVersion.2.8.6=upgrade-db-to-2.8.6
database.upgradeVersion.2.8.7=upgrade-db-to-2.8.7
database.upgradeVersion.2.9.0=upgrade-db-to-2.9.0
database.upgradeVersion.2.10.0=upgrade-db-to-2.10.0
database.upgradeVersion.2.10.1=upgrade-db-to-2.10.1
database.upgradeVersion.2.10.2=upgrade-db-to-2.10.2
database.upgradeVersion.2.10.3=upgrade-db-to-2.10.3
database.upgradeVersion.2.10.4=upgrade-db-to-2.10.4
database.upgradeVersion.2.11.0=upgrade-db-to-2.11.0
database.upgradeVersion.2.11.1=upgrade-db-to-2.11.1
database.upgradeVersion.2.12.0=upgrade-db-to-2.12.0
database.upgradeVersion.2.12.1=upgrade-db-to-2.12.1
database.upgradeVersion.2.12.2=upgrade-db-to-2.12.2
database.upgradeVersion.2.12.3=upgrade-db-to-2.12.3
database.upgradeVersion.2.12.4=upgrade-db-to-2.12.4
database.upgradeVersion.2.13.0=upgrade-db-to-2.13.0
database.upgradeVersion.2.14.0=upgrade-db-to-2.14.0
database.upgradeVersion.2.14.1=upgrade-db-to-2.14.1
database.upgradeVersion.2.15.0=upgrade-db-to-2.15.0
database.upgradeVersion.2.15.1=upgrade-db-to-2.15.1
database.upgradeVersion.2.16.0=upgrade-db-to-2.16.0
database.upgradeVersion.2.16.1=upgrade-db-to-2.16.1
database.upgradeVersion.2.16.2=upgrade-db-to-2.16.2
database.upgradeVersion.2.17.0=upgrade-db-to-2.17.0
database.upgradeVersion.2.18.0=upgrade-db-to-2.18.0
database.upgradeVersion.2.19.0=upgrade-db-to-2.19.0
database.upgradeVersion.2.19.1=upgrade-db-to-2.19.1

## for running java-based utilities
database.upgradeUtility.1.5.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade1_5_0
database.upgradeUtility.2.0.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_0_0
## for running java-based solr upgrader. It should look like:
#solr.upgradeUtility.2.9.0=

database.initialConnections=5
database.incrementConnections=5
# be sure to increase SQL connection limits accordingly:
database.maximumConnections=200
database.maximumConnectionAge=120000
database.maximumConnectionTime=60000
database.maximumUsageNumber=100
database.connectionCountWarnLimit=15
database.numberOfIndexingThreads=5
database.indexingTimerTaskTime=604800000
database.indexingInitialDelay=3600000
database.maximumIndexDelay=5000
database.runDBConnectionRecycleThread=off
database.cycleTimeOfDBConnection=30000
database.queryignoredparams=enableediting,foo
database.usexmlindex=true
# used for the setting the size of resultset for applications like morpho
database.appResultsetSize=7000
# used for the setting the size of resultset for searches done using browsers
database.webResultsetSize=7000
# the value of xml_returnfield.usage_count should be more than this value
# for records to be entered into xml_queryresult. so if you want results for
# any combination of returnfields to be stored in xml_queryresult only when
# that combination has been requested 50 times, set this value to 50
database.xmlReturnfieldCount=0
# used for the setting the size of queryresult_string in queryresult table.
# the limit is 4000 for oracle
database.queryresultStringLength=500000
#the size of query result cache
database.queryresultCacheSize=500
#turn on or off the query result cache
database.queryCacheOn=true
#the time in milliseconds that an squery can run before metacat logs a warning
database.queryTimeWarnLimit=30000
#the time in milliseconds that an squery can run before metacat logs a warning
database.squeryTimeWarnLimit=30000


######## DB Query section              #######################################
dbquery.enabledEngines=pathquery;solr
#the time in milliseconds that a stylesheet transform can run before metacat logs a warning
dbquery.transformTimeWarnLimit=60000
#the time in milliseconds to get a document list before metacat logs a warning
dbquery.findDocListTimeWarnLimit=60000
#the time in milliseconds to get return values from queryresults table before metacat logs a warning
dbquery.findQueryResultsTimeWarnLimit=60000
#the time in milliseconds to run extended (index and node) queries before metacat logs a warning
dbquery.extendedQueryRunTimeWarnLimit=60000
#the time in milliseconds to store return fields before metacat logs a warning
dbquery.storeReturnFieldTimeWarnLimit=60000
#the time in milliseconds to totally process return fields before metacat logs a warning
dbquery.totalReturnFieldTimeWarnLimit=120000
#when the servlet initializes, if we need to check to see if new paths were added
dbquery.init.check.newpath=false

######## Datamanager section              #######################################
datamanager.adapter=PostgresAdapter
datamanager.implementation=edu.ucsb.nceas.metacat.dataquery.PostgresDatabaseConnectionPool
datamanager.server=localhost
datamanager.database=datamanager
datamanager.user=datamanager
datamanager.password=datamanager
datamanager.maxconnections=10

#datamanager.endpoint.query=http://ecogrid.ecoinformatics.org/metacat/services/QueryService
#datamanager.endpoint.authenticatedquery=http://ecogrid.ecoinformatics.org/metacat/services/AuthenticatedQueryService
#datamanager.endpoint.authentication=http://ecogrid.ecoinformatics.org/metacat/services/AuthenticationService
#datamanager.endpoint.put=http://ecogrid.ecoinformatics.org/metacat/services/PutService
#datamanager.endpoint.identifier=http://ecogrid.ecoinformatics.org/metacat/services/IdentificationService
#datamanager.srb.endpoint=
#datamanager.srb.machinename=

######## Plugin section              #######################################
plugin.handlers=

######## Authentication  ##############################################

auth.class=edu.ucsb.nceas.metacat.authentication.AuthFile
#auth.class=edu.ucsb.nceas.metacat.AuthLdap
# Use AuthStub to test and guarantee authentication
#auth.class=edu.ucsb.nceas.metacat.AuthStub
#auth.administrators=uid=jones,o=NCEAS,dc=ecoinformatics,dc=org
auth.administrators=
auth.userManagementUrl=
#The list of auth.allowedSubmitters(auth.administrators,auth.deniedSubmitters and auth.moderators) should be separated by colon (:). If the individual value has the colon as well, the colon should be escaped by backslash (\).
#For example, auth.allowedSubmitters=http\://orcid.org/0000-0002-1209-5268:cn=parc,o=PARC,dc=ecoinformatics,dc=org
auth.allowedSubmitters=
auth.deniedSubmitters=
auth.moderators=
#auth.moderators=cn=knb-prod,o=NCEAS,dc=ecoinformatics,dc=org
#auth.moderators=cn=knb-prod,o=NCEAS,dc=ecoinformatics,dc=org:cn=esa-moderators,dc=ecoinformatics,dc=org:cn=parc-moderators,o=PARC,dc=ecoinformatics,dc=org
auth.defaultUserManagementPage=/style/common/default-user-management.jsp
# the size of the cache storing group information in the AuthSession class
auth.groupCacheSize=200
#####File-based Authentication######
auth.file.path=/var/metacat/users/password.xml
auth.file.hashClassName=edu.ucsb.nceas.metacat.authentication.AuthFileBCryptHash
######LDAP-based Authentication#############
auth.timeoutMinutes=180
auth.url=ldap://ldap.ecoinformatics.org:389/
auth.surl=ldap://ldap.ecoinformatics.org:389/
auth.base=dc=ecoinformatics,dc=org
# time in milliseconds allowed for ldap server connections
ldap.connectTimeLimit=5000
# time in milliseconds allowed for ldap server searches
ldap.searchTimeLimit=30000
# count of return entries allowed for ldap server searches
ldap.searchCountLimit=30000
ldap.referral=follow
ldap.onlySecureConnection=false
ldap.onlySecureReferalsConnection=false
ldap.server.ca.certificate=
ldap.nextuid.storing.dn=cn=uidNext,dc=ecoinformatics,dc=org
ldap.nextuid.storing.attributename=description
ldap.nextuid.maxattempt=300
ldap.recaptcha.publickey=yourPublicKey
ldap.recaptcha.privatekey=yourPrivateKey
ldap.web.startTLS=false

# LDAP templates
ldap.templates.stage=initregister
ldap.templates.header=genericHeader.tmpl
ldap.templates.footer=genericFooter.tmpl
ldap.templates.changePass=ldapChangePass.tmpl
ldap.templates.changePassSuccess=ldapChangePassSuccess.tmpl
ldap.templates.resetPass=ldapResetPass.tmpl
ldap.templates.resetPassSuccess=ldapResetPassSuccess.tmpl
ldap.templates.register=ldapRegister.tmpl
ldap.templates.registerFailed=ldapRegisterFailed.tmpl
ldap.templates.registerMatch=ldapRegisterMatch.tmpl
ldap.templates.registerSuccess=ldapRegisterSuccess.tmpl
ldap.templates.verificationSuccess=ldapVerificationSuccess.tmpl
ldap.templates.verificationFailed=ldapVerificationFailed.tmpl
ldap.templates.registerLter=ldapRegisterLter.tmpl
ldap.templates.success=ldapRegisterSuccess.tmpl
ldap.templates.failed=ldapRegisterFailed.tmpl
ldap.templates.mainServerFailure=ldapMainServerFailure.tmpl
ldap.templates.searchResults=searchResults.tmpl
ldap.templates.lookupName=ldapLookupName.tmpl
ldap.templates.lookupNameSuccess=ldapLookupNameSuccess.tmpl
#The property defines a default value which controls the list of organization names showing in the account registration,
#password reset and change password templates for all skins.
#The value of the property will be overwritten if a skin properties file defines the property as well.
#The value of the property should be defined in the organization.name.VALUE=something in the organization part.
#Multiple values will be separated by ";".
ldap.templates.organizationList=unaffiliated

############### Session Values ###############
session.timeoutMinutes=360

############### Event Log Values ###############

#The events involved with the list of event.log.blacklist.ipaddres and event.log.blacklist.subject will NOT be logged into db.
#If they are blank, it means every ip address and subject will be logged. The individual values should be separated by colon (:).
#If the individual value has the colon as well, the colon should be escaped by backslash (\).
#For example, event.log.blacklist.subject=http\://orcid.org/0000-0002-1209-5268:cn=parc,o=PARC,dc=ecoinformatics,dc=org
event.log.blacklist.ipaddress=
event.log.blacklist.subject=

############### Organization Values ###############
organization.configured.NCEAS=false
organization.name.NCEAS=National Center for Ecological Analysis and Synthesis
organization.label.NCEAS=NCEAS
organization.password.NCEAS=
organization.expiration.NCEAS=36
organization.configured.OBFS=false
organization.name.OBFS=Organization of Biological Field Stations
organization.configured.OSUSB=false
organization.name.OSUSB=
organization.configured.UCNRS=false
organization.name.UCNRS=University of California Natural Reserve System
organization.base.UCNRS=ou=people,o=ucnrs.org
organization.user.UCNRS=uid=nrsadmin,o=NCEAS,dc=ecoinformatics,dc=org
organization.password.UCNRS=
organization.configured.KU=false
organization.name.KU=
organization.configured.LTER=false
organization.name.LTER=
organization.configured.UVM=false
organization.name.UVM=
organization.configured.SDSC=false
organization.name.SDSC=
organization.configured.MSU=false
organization.name.MSU=
organization.configured.NAPIER=false
organization.name.NAPIER=
organization.configured.SANPARKS=false
organization.name.SANPARKS=Kruger National Park
organization.org.SANPARKS=o=SANPARKS
organization.configured.SAEON=false
organization.name.SAEON=South African Environmental Observation Network Repository
organization.org.SAEON=o=SAEON

organization.name.unaffiliated=unaffiliated
organization.base.unaffiliated=dc=ecoinformatics,dc=org
organization.org.unaffiliated=o=unaffiliated
organization.user.unaffiliated=cn=Manager
organization.password.unaffiliated=
organization.expiration.unaffiliated=36
organization.label.unaffiliated=KNB/AOOS


organization.name.Account=Account
organization.base.Account=dc=ecoinformatics,dc=org
organization.org.Account=ou=Account
organization.user.Account=cn=Manager
organization.password.Account=
organization.expiration.Account=36
organization.label.Account=NCEAS/DataONE/Kepler

######## XML / EML  #########################################

xml.saxparser=org.apache.xerces.parsers.SAXParser
xml.eml2_0_0namespace=eml://ecoinformatics.org/eml-2.0.0
xml.eml2_0_1namespace=eml://ecoinformatics.org/eml-2.0.1
xml.eml2_1_0namespace=eml://ecoinformatics.org/eml-2.1.0
xml.eml2_1_1namespace=eml://ecoinformatics.org/eml-2.1.1
xml.eml2_2_0namespace=https://eml.ecoinformatics.org/eml-2.2.0
xml.rdf_syntax_namespace=http://www.w3.org/1999/02/22-rdf-syntax-ns#
xml.useFullSchemaValidation=true
xml.packagedoctype=-//ecoinformatics.org//eml-dataset-2.0.0beta6//EN, -//ecoinformatics.org//eml-dataset-2.0.0beta4//EN
xml.accessdoctype=-//ecoinformatics.org//eml-access-2.0.0beta6//EN, -//ecoinformatics.org//eml-access-2.0.0beta4//EN
xml.physicaldoctype=-//ecoinformatics.org//eml-physical-2.0.0beta6//EN, -//ecoinformatics.org//eml-physical-2.0.0beta4//EN
xml.entitydoctype=-//ecoinformatics.org//eml-entity-2.0.0beta6//EN, -//ecoinformatics.org//eml-entity-2.0.0beta4//EN
xml.packagedoctypeset=BIN,-//ecoinformatics.org//eml-access-2.0.0beta6//EN,-//ecoinformatics.org//eml-access-2.0.0beta4//EN,-//ecoinformatics.org//eml-attribute-2.0.0beta6//EN,-//ecoinformatics.org//eml-attribute-2.0.0beta4//EN,-//ecoinformatics.org//eml-constraint-2.0.0beta6//EN,-//ecoinformatics.org//eml-constraint-2.0.0beta4//EN,-//ecoinformatics.org//eml-coverage-2.0.0beta6//EN,-//ecoinformatics.org//eml-coverage-2.0.0beta4//EN,-//ecoinformatics.org//eml-dataset-2.0.0beta6//EN,-//ecoinformatics.org//eml-dataset-2.0.0beta4//EN,-//ecoinformatics.org//eml-entity-2.0.0beta6//EN,-//ecoinformatics.org//eml-entity-2.0.0beta4//EN,-//ecoinformatics.org//eml-literature-2.0.0beta6//EN,-//ecoinformatics.org//eml-literature-2.0.0beta4//EN,-//ecoinformatics.org//eml-physical-2.0.0beta6//EN,-//ecoinformatics.org//eml-physical-2.0.0beta4//EN,-//ecoinformatics.org//eml-project-2.0.0beta6//EN,-//ecoinformatics.org//eml-project-2.0.0beta4//EN,-//ecoinformatics.org//eml-protocol-2.0.0beta6//EN,-//ecoinformatics.org//eml-protocol-2.0.0beta4//EN,-//ecoinformatics.org//eml-software-2.0.0beta6//EN,-//ecoinformatics.org//eml-software-2.0.0beta4//EN
xml.indexNamespaces=eml://ecoinformatics.org/eml-2.0.0,eml://ecoinformatics.org/eml-2.0.1,eml://ecoinformatics.org/eml-2.1.0,eml://ecoinformatics.org/eml-2.1.1,https://eml.ecoinformatics.org/eml-2.2.0,http://www.kepler-project.org/kar-2.0.0,http://www.kepler-project.org/kar-2.1.0
xml.indexPaths=                            \
	@packageId,                            \
	/reviewHistory/review/packageId,       \
	abstract,                              \
	abstract/value,                        \
	abstract/para,                         \
	abstract/para/value,                   \
	access/allow/principal,                \
	additionalMetadata/metadata/spatialResolution/value,	\
	additionalMetadata/metadata/spatialResolution/units,	\
	additionalMetadata/moderatorComment,   \
	associatedParty/individualName/surName,                           \
	associatedParty/organizationName,                                 \
	coverage/temporalCoverage/rangeOfDates/beginDate/alternativeTimeScale/timeScaleName,   \
	coverage/temporalCoverage/rangeOfDates/endDate/alternativeTimeScale/timeScaleName,     \
	coverage/temporalCoverage/singleDateTime/alternativeTimeScale/timeScaleName,           \
	coverage/temporalCoverage/rangeOfDates/beginDate/calendarDate,   \
	coverage/temporalCoverage/rangeOfDates/endDate/calendarDate,     \
	coverage/temporalCoverage/singleDateTime/calendarDate,           \
	coverage/temporalCoverage/rangeOfDates/beginDate/time,   \
	coverage/temporalCoverage/rangeOfDates/endDate/time,     \
	coverage/temporalCoverage/singleDateTime/time,           \
	creator/individualName/surName,        \
	creator/individualName/givenName,      \
	creator/organizationName,              \
	dataset/access/allow/principal,        \
	dataset/dataTable/physical/distribution/online/url,               \
	dataset/dataTable/physical/distribution/online/url/@function,     \
	dataset/spatialRaster/physical/distribution/online/url,           \
	dataset/spatialRaster/physical/distribution/online/url/@function, \
	dataset/otherEntity/physical/distribution/online/url,           \
	dataset/otherEntity/physical/distribution/online/url/@function, \
	physical/encodingMethod, \
	dataset/title,                         \
	dataset/title/value,                   \
	eastBoundingCoordinate,                \
	eastbc,                                \
	EcogridRegEntry/description,           \
	EcogridRegEntry/endPoint,              \
	EcogridRegEntry/serviceName,           \
	entityName,                            \
	geographicCoverage/boundingCoordinates/eastBoundingCoordinate,    \
	geographicCoverage/boundingCoordinates/northBoundingCoordinate,   \
	geographicCoverage/boundingCoordinates/southBoundingCoordinate,   \
	geographicCoverage/boundingCoordinates/westBoundingCoordinate,    \
	geographicDescription,                 \
	givenName,                             \
	idinfo/citation/citeinfo/title,        \
	idinfo/citation/citeinfo/origin,       \
	idinfo/keywords/theme/themekey,        \
	individualName/surName,                \
	keyword,                               \
	karEntry/karEntryAttributes/type,      \
	karEntry/karEntryXML/property/property/@name,           \
	karEntry/karEntryXML/property/property/@value,          \
	karEntry/karEntryXML/property/property/property/@name,  \
	karEntry/karEntryXML/property/property/property/@value, \
	karFileName,                           \
	karFileSize,                           \
	keyword/value,                         \
	literalLayout,                         \
	mainAttributes/lsid,                   \
	northbc,                               \
	northBoundingCoordinate,               \
	organizationName,                      \
	originator/individualName/surName,     \
	originator/individualName/givenName,   \
	originator/organizationName,           \
	para,                                  \
	placekey,                              \
	southBoundingCoordinate,               \
	southbc,                               \
	surName,                               \
	taxonomicClassification/taxonRankName,          \
	taxonomicClassification/taxonRankValue,         \
	taxonRankValue,                        \
	title,                                 \
	westBoundingCoordinate,                \
	westbc

######## Outgoing email  #########################################

email.mailhost=localhost
email.sender=knb-software@nceas.ucsb.edu
email.contact=knb-software@nceas.ucsb.edu
email.admin=KNB Support
email.recipient=knb-software@nceas.ucsb.edu

######## Replication properties  #########################################

replication.logdir=
## deltaT=60
## debuglevel=55
replication.datafileflag=datafile
## TODO MCD this seems to be used in other placed besides replication
replication.datafilesizelimit=1000
replication.defaultcontenttype=application/octet-stream
replication.timedreplication=false
replication.firsttimedreplication=10:00 PM
replication.timedreplicationinterval=172800000
replication.forcereplicationwaitingtime=30000
replication.client.timeout=60000
# certificate-based replication configuration
replication.certificate.file=/etc/dataone/client/certs/METACAT1.pem
replication.privatekey.file=/etc/dataone/client/certs/METACAT1.pem
replication.privatekey.password=


######## Skins  #########################################

skin.names=default,metacatui,nceas,esa,knb,kepler,lter,ltss,obfs,nrs,sanparks,saeon,first,parc,dataone

############# UI Section ###########################################
ui.context=metacatui

######## Document Section  #########################################

#The flag to indicate if invalidated eml 201 documents were corrected.
#Before Metacat 1.8.1, metacat uses tag RELEASE_EML_2_0_1_UPDATE_6 as eml
#schema, which accidentily points to wrong version of eml-resource.xsd.
#If this value is false, metacat will run a class to correct eml201 doucment.
document.eml201DocumentCorrected=true
document.sitecode=nceas
document.accNumSeparator=.
document.accNumPrefix=autogen

######## Harvester section            #########################################

harvester.connectToMetacat=true
harvester.delay=0
harvester.administrator=name@institution.edu
harvester.logPeriod=90
harvester.maxHarvests=0
harvester.period=24
harvester.smtpServer=localhost
harvester.GetDocError=Error getting EML document from site,Error
harvester.GetDocSuccess=Success getting EML document from site,Debug
harvester.GetHarvestListError=Error getting harvest list from site,Error
harvester.GetHarvestListSuccess=Success getting harvest list from site,Debug
harvester.HarvesterStartup=Harvester start up,Info
harvester.HarvesterShutdown=Harvester shut down,Info
harvester.InsertDocError=Error inserting EML document to Metacat,Error
harvester.InsertDocSuccess=Success inserting EML document to Metacat,Info
harvester.MetacatHasDoc=Metacat already has this EML document,Info
harvester.UpdateDocError=Error updating EML document to Metacat,Error
harvester.UpdateDocSuccess=Success updating EML document to Metacat,Info
harvester.ValidateDocError=Error validating EML docoument,Error
harvester.ValidateDocSuccess=Success validating EML document,Debug
harvester.ValidateHarvestListError=Error validating harvest list,Error
harvester.ValidateHarvestListSuccess=Success validating harvest list,Debug

######## OAI-PMH section              #######################################

oaipmh.maxListSize=5
oaipmh.repositoryIdentifier=localhost:8080
AbstractCatalog.oaiCatalogClassName=edu.ucsb.nceas.metacat.oaipmh.provider.server.catalog.MetacatCatalog
AbstractCatalog.recordFactoryClassName=edu.ucsb.nceas.metacat.oaipmh.provider.server.catalog.MetacatRecordFactory
# Duration of resumption tokens
AbstractCatalog.secondsToLive=3600
# Choose one of the following two
AbstractCatalog.granularity=YYYY-MM-DD
#AbstractCatalog.granularity=YYYY-MM-DDThh:mm:ssZ
# Custom Identify response values
Identify.repositoryName=Local Metacat OAI-PMH Data Provider
Identify.adminEmail=mailto:admin@localhost
Identify.earliestDatestamp=2000-01-01T00:00:00Z
Identify.deletedRecord=no
# Append something unique like .1, .2, etc to 'Identify.description' for each occurrence
#Identify.description.1=<description><oai-identifier xmlns\="http\://www.openarchives.org/OAI/2.0/oai-identifier" xmlns\:xsi\="http\://www.w3.org/2001/XMLSchema-instance" xsi\:schemaLocation\="http\://www.openarchives.org/OAI/2.0/oai-identifier http\://www.openarchives.org/OAI/2.0/oai-identifier.xsd"><scheme>oai</scheme><repositoryIdentifier>metacat.lternet.edu</repositoryIdentifier><delimiter>\:</delimiter><sampleIdentifier>http\://metacat.lternet.edu/metacat/metacat/knb-lter-lno.1</sampleIdentifier></oai-identifier></description>
# List the supported metadataPrefixes along with the class that performs the associated crosswalk
Crosswalks.oai_dc=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml2oai_dc
Crosswalks.eml-2.0.0=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml200
Crosswalks.eml-2.0.1=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml201
Crosswalks.eml-2.1.0=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml210
Crosswalks.eml-2.1.1=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml211

######## Spatial section              #########################################

spatial.runSpatialOption=false
spatial.regenerateCacheOnRestart=false
# Comma-seperated list of schemas containing spatial bounding boxes
# name corresponds to the docname stored in xml_documents table
spatial.spatialDocnameList=eml,fgdc,metadata
# XML paths to the four bounding coordinates
# These paths must be included in your indexPaths variable in build.properties
# Note the naming convention:
#   {docname}_{direction}BoundingCoordinatePath=.....
# Has not been tested with other schemas besides EML
spatial.eml_westBoundingCoordinatePath=geographicCoverage/boundingCoordinates/westBoundingCoordinate
spatial.eml_eastBoundingCoordinatePath=geographicCoverage/boundingCoordinates/eastBoundingCoordinate
spatial.eml_southBoundingCoordinatePath=geographicCoverage/boundingCoordinates/southBoundingCoordinate
spatial.eml_northBoundingCoordinatePath=geographicCoverage/boundingCoordinates/northBoundingCoordinate
spatial.fgdc_westBoundingCoordinatePath=spdom/bounding/westbc
spatial.fgdc_eastBoundingCoordinatePath=spdom/bounding/eastbc
spatial.fgdc_southBoundingCoordinatePath=spdom/bounding/southbc
spatial.fgdc_northBoundingCoordinatePath=spdom/bounding/northbc
spatial.metadata_westBoundingCoordinatePath=westbc
spatial.metadata_eastBoundingCoordinatePath=eastbc
spatial.metadata_southBoundingCoordinatePath=southbc
spatial.metadata_northBoundingCoordinatePath=northbc
spatial.docTitle=dataset/title

######## Sitemap section              #########################################
sitemap.enabled=true
# Sitemap Interval (in milliseconds) between rebuilding the sitemap
sitemap.interval=86400000
# Base part of the URLs for the location of the sitemap files themselves.
# Either full URL or absolute path. Trailing slash optional.
sitemap.location.base=/metacatui
# Base part of the URLs for the location entries in the sitemaps which should
# be the base URL of the dataset landing page.
# Either full URL or absolute path. Trailing slash optional.
sitemap.entry.base=/metacatui/view
# Optional Portal configuration for sitemaps
# If set, sitemap entries for metadata with a format equal to one of
# sitemap.entry.portal.formats will use sitemap.entry.portal.base instead of
# sitemap.entry.base for its sitemap URLs.
sitemap.entry.portal.base=/metacatui/portals
sitemap.entry.portal.formats=https://purl.dataone.org/portals-1.0.0

######## Workflow engine section              #########################################
executionEngine.workflowRunEngineName=localWorkflowEngine
executionEngine.endPointAddress=http://localhost/workflowrunengine/services/KeplerWebService
executionEngine.resultDestinationRepository=sanparksRepository:keplerRepository:keplerDevRepository:chico1Repository
######## junit test section  ################

test.printdebug=true
test.mcUser=uid=kepler,o=unaffiliated,dc=ecoinformatics,dc=org
test.mcPassword=kepler
test.mcAnotherUser=uid=test,o=NCEAS,dc=ecoinformatics,dc=org
test.mcAnotherPassword=test
test.mcThirdUser=http://orcid.org\0023-0001-7868-2567
test.mcThirdPassword=test
test.usrGroup=CN=ess-dive-test-users,DC=dataone,DC=org
test.referralUser=uid=testreferral,o=UCNRS,dc=ecoinformatics,dc=org
test.referralPassword=testreferral
test.lterUser=uid=knbuser,o=LTER,dc=ecoinformatics,dc=org
test.lterPassword=b1gf1$h
test.piscoUser=uid=piscotest,o=PISCO,dc=ecoinformatics,dc=org
test.piscoPassword=testPW
test.testProperty=testing
test.replication.targetServer=mn-demo-6.test.dataone.org/knb
test.dataone.replication.sourceNodeId=urn:node:mnSandboxUCSB1
test.dataone.replication.waitingTime=5000
#test.dataone.replication.waitingTime=480000

######## Developers Section #########################################

# Set dev.runConfiguration to false to keep the system from walking you
# through the configuration utility every time you reinstall metacat.
# Instead,  the system will use backed up configuration values.  If you
# haven't ever configured the app (no backup files) the system will take
# you through the configuration.
dev.runConfiguration=true


############# DataONE Section #######################################
D1Client.CN_URL=https://cn.dataone.org/cn
# Configure the Member Node client certificate location
D1Client.certificate.file=/var/metacat/certs/METACAT1.pem
# Client resources
D1Client.resourcesDir=/var/metacat/dataone
# Member Node configuration
dataone.nodeId=urn:node:METACAT_TEST
dataone.subject=CN=urn:node:METACAT1,DC=dataone,DC=org
dataone.contactSubject=CN=Scientist 1234,DC=dataone,DC=org
dataone.nodeName=My Metacat Node
dataone.nodeType=mn
dataone.nodeDescription=Describe your Member Node briefly.
dataone.nodeSynchronize=false
dataone.nodeReplicate=false
dataone.serviceName=d1
dataone.mn.baseURL=
dataone.nodeToken.file=/var/metacat/certs/token

# the synchronization schedule
dataone.nodeSynchronization.schedule.year=*
dataone.nodeSynchronization.schedule.mon=*
dataone.nodeSynchronization.schedule.mday=*
dataone.nodeSynchronization.schedule.wday=?
dataone.nodeSynchronization.schedule.hour=*
dataone.nodeSynchronization.schedule.min=0/3
dataone.nodeSynchronization.schedule.sec=10

# The default replication policy
dataone.replicationpolicy.default.numreplicas=0
dataone.replicationpolicy.default.preferredNodeList=
dataone.replicationpolicy.default.blockedNodeList=

# The default node replication policy
dataone.node.replicationpolicy.maxObjectSize=-1
dataone.node.replicationpolicy.spaceAllocated=-1
# If the allowedNode value is blank, any nodes will be allowed; otherwise, only the list of the nodes will be allowed
# The value of allowedNode should be the node id. If it has multiple values, they should be separated by ;
dataone.node.replicationpolicy.allowedNode=
# If the allowedObjectFormat value is blank, any formats will be allowed; otherwise, only the list of the formats will be allowed
# The value of allowedObjectFormat should be the format id. If it has multiple values, they should be separated by ;
dataone.node.replicationpolicy.allowedObjectFormat=

# Default checksum algorithm
dataone.checksumAlgorithm.default=MD5

# Default file upload size for create() and update (in bytes, or -1 for no limit)
# Note that this is parsed as an int value, so must be < 2^31-1
dataone.max_upload_size=1000000000

# overall services (TODO: mn vs. cn?)
dataone.mn.services.enabled=true
dataone.mn.registration.submitted=false

# state which versions of each MN tier service are availalble
dataone.mnCore.serviceAvailable=true;true
dataone.mnCore.serviceVersion=v1;v2
dataone.mnRead.serviceAvailable=true;true
dataone.mnRead.serviceVersion=v1;v2
dataone.mnAuthorization.serviceAvailable=true;true
dataone.mnAuthorization.serviceVersion=v1;v2
dataone.mnStorage.serviceAvailable=true;true
dataone.mnStorage.serviceVersion=v1;v2
dataone.mnReplication.serviceAvailable=true;true
dataone.mnReplication.serviceVersion=v1;v2
dataone.mnPackage.serviceAvailable=true;true
dataone.mnPackage.serviceVersion=v1;v2
dataone.mnView.serviceAvailable=true
dataone.mnView.serviceVersion=v2

# The DataONE storage cluster configuration for Hazelcast
#dataone.hazelcast.configFilePath=/etc/dataone/storage/hazelcast.xml
dataone.hazelcast.storageCluster.systemMetadataMap=hzSystemMetadata
dataone.hazelcast.storageCluster.objectPathMap=hzObjectPath
dataone.hazelcast.storageCluster.identifiersSet=hzIdentifiers
dataone.hazelcast.storageCluster.tasksIdNamespace=task-ids

# Parameters for connecting to the DataONE process cluster as a Hazelcast client
dataone.hazelcast.processCluster.groupName=dev
dataone.hazelcast.processCluster.password=dataone
dataone.hazelcast.processCluster.instances=127.0.0.1
dataone.hazelcast.processCluster.nodesMap=hzNodes

# DataONE types XSLT
dataone.types.xsl.v1=/cn/xslt/dataone.types.v1.xsl
dataone.types.xsl.v2=/cn/xslt/dataone.types.v2.xsl


# DataONE configuration settings
dataone.ore.downloaddata=false
dataone.ore.generated=false
dataone.systemmetadata.generated=false


# DataONE http client settings
# increased from 5
D1Client.http.maxConnectionsPerServer=50

# increased from 200
D1Client.http.maxConnectionsTotal=500

# X509 client authentication forwarding using HTTP headers:
# Disable/enable the proxy forwarding of client X509 certificates and subjects from an upstream web server
# Do not enable this feature unless:
#    1. Your web server performing SSL termination and your Metacat server are on the same trusted private network
#    2. The X509 client certificates have been verified by your upstream trusted web server, and 
#    3. The certificate information in the HTTP headers are only set by the upstream trusted web server. 
# Using this feature in any other manner can result in security vulnerabilities.  It is only intended for
# groups using containerized systems and their internal networks. 
# Please do NOT enable it unless you understand what you are doing.
dataone.certificate.fromHttpHeader.enabled=false
# Set a shared secret between you trusted upstream web server and Metacat
# Please use a long random string which is shared by Metacat and your web server.
# The web server must send HTTP requests to Metacat with an "X-Proxy-Key" HTTP header,
# with the random string as a value.
dataone.certificate.fromHttpHeader.proxyKey=

# Disable or enable the quotas service. Now the replication quota service is alway disabled. 
dataone.quotas.storage.enabled=false
dataone.quotas.portals.enabled=false
dataone.quotas.replication.enabled=false
dataone.quotas.bookkeeper.serviceUrl=https://api.dataone.org/bookkeeper/v1/
dataone.quotas.reportingThreadPoolSize=5
# The time in every day to report the usages again,  which failed to be reported to the remote server at the first place
dataone.quotas.dailyReportingUsagesTime=11:00 PM
# use ; to separate multiple name spaces.
dataone.quotas.portal.namespaces=https://purl.dataone.org/portals-1.0.0;https://purl.dataone.org/portals-1.1.0

# Enable Metacat to append ldap groups to a session
dataone.session.appendLdapGroups.enabled=true

############# Global Identifiers Assignment Section ######################
guid.doiservice.plugin.class=edu.ucsb.nceas.metacat.doi.ezid.EzidDOIService
#guid.doiservice.plugin.class=edu.ucsb.nceas.metacat.doi.osti.OstiDOIService
guid.assignGUIDs=false
guid.doi.enabled=false
guid.doi.username=apitest
guid.doi.password=
guid.doi.baseurl=https://ezid.cdlib.org/
guid.doi.autoPublish=true
#When users publish a package, the metadata object and resource map will be forced to public readable even though they are private now.
#If enforcePublicReadableEntirePackage is true, the data objects will be forced to public readable even though they are private;
#otherwise, the data objects will keep private as they are. 
guid.doi.enforcePublicReadableEntirePackage=true
#guid.doi.baseurl=https://n2t.net/ezid/
# optional path for target. do not include hostname here. <IDENTIFIER> is replaced with real value
guid.doi.uritemplate.metadata=/metacatui/view/<IDENTIFIER>
#guid.doi.uritemplate.data=
#The first shoulder is the primary one. It is used for minting (generating) and creating (registering) DOIs.
guid.doi.doishoulder.1=doi:10.5072/FK2
#The following commented shoulder is for testing OSTI
#guid.doi.doishoulder.1=doi:10.15485/
#The second and beyond shoulders are only for creating (registering) DOIs. You need to generate a unique DOI by yourself.
guid.doi.doishoulder.2=
#The following commented shoulder is for testing OSTI
#guid.doi.doishoulder.2=doi:10.5072/
#Email settings for sending errors. Now it only works with OSTI
guid.doi.mail.smtp.host=localhost
guid.doi.mail.smtp.port=587
guid.doi.mail.to=tao@nceas.ucsb.edu
guid.doi.mail.from=tao@nceas.ucsb.edu
#The factory classes can generate the datacite document. It should be sperator by ';' if it has multiple values.
guid.ezid.datacite.factories=edu.ucsb.nceas.metacat.doi.datacite.EML2DataCiteFactory

############# Index Section ###########################################
#The md5 hash numbers for the schema.xml in previous releases. It should be sperator by ';' if it has multiple values.
index.schema.previous.hash=8b18d7ed4a5364159adeb507f004e5de;714457a3cdd05e034e5df46589b3bfa9;ba7dc67bbf749b02e03d7b7cc6a31def;ebf5b20f9cd18d31c3a6057749ba9397;fb1f63a36f2c742f1ba144d559c37075;2acacecbb55721806b7e92d7a115c35a;3418ed9d10bbc70f1e8020233d954f83;a54e667426384f89106405263df77373;8fc703ec01ef6d4cb413d9c2fbced532;25f1b66f3a25e1c80adf86e48f1838bb;1a0f05c01c5714737a1efc992b262e7e;20ccd7b01985707bfc870f27713f859f;fc009d4387e84abf153cd416197114c2;7e88ec7922c18e56aa9a2d316d1a37bc;941e4b42858e82c69e0e7d6abd97cd55
#The md5 hash number for the schema.xml in this release
index.schema.current.hash=941e4b42858e82c69e0e7d6abd97cd55
index.configFile.released.hash=076e8c421c95f6c1aceb1c0e3dd3042b;09adcfa08f96179dfddf9e43899b9181;58c1dcc343ee87d8fc133008571b856a
index.configFile.current.hash=58c1dcc343ee87d8fc133008571b856a
index.context=metacat-index
index.resourcemap.namespace=http://www.w3.org/TR/rdf-syntax-grammar;http://www.openarchives.org/ore/terms
#The process to regenerate the index when the metacat-index web app starts needs the readiness of the metacat.
#The index.regenerate.start.waitingtime (in milliseconds) and index.regenerate.start.maxattempts are used to control the waiting time.
index.regenerate.start.waitingtime=10000
index.regenerate.start.maxattempts=600
#An interval to run the thread to regenerate solr index which failed before.
#If the inerval is less than 0, the thread would not run.
index.regenerate.interval=86400000
#The time for first time to run the regenerate thread. It should like this format--10:00 AM
index.regenerate.firsttime=11:50 PM
#If we want to reindex previous failed index tasks
index.regenerate.failedObject=true
#The max age of failed index tasks will be reindexed. If their age is greater than the number, they will be ignored.
index.regenerate.failedTask.max.age=864000000
#If we want to reindex objects whose modified date is younger than the last process date
index.regenerate.sincelastProcessDate=true
index.eventlog.classname=edu.ucsb.nceas.metacat.index.event.HazelcastIndexEventLog
index.hazelcast.indexqueue=hzIndexQueue
index.hazelcast.indexeventmap=hzIndexEventMap
index.tdb.directory=/var/metacat/tdb
index.accessLog.count.enabled=false
#The time (millisecond) that the resource map processor waits for the solr doc readiness of its components 
index.resourcemap.waitingComponent.time=600
#The number of the attempts that the resource map processor tries to wait for the solr doc readiness of its components
index.resourcemap.waitingComponent.max.attempts=15
#The time (millisecond) that indexer will wait to grab a newer version of solr doc when a version conflict happened 
index.solr.versionConflict.waiting.time=500
#The number of the attempts that indexer tries to grab a newer version of solr doc when a version conflict happened 
index.solr.versionConflict.max.attempts=5
#You may specify the exact number of threads the indexer will use. 
#If you keep it blank, Metacat will use the default one - the system processors number minus one. If calculation result is 0, 1 will be used as the default value.
#If the one you specify exceeds the default number or is less than 1, the default one will be used as well.
index.thread.number=

#The locations for the context files used in the schema.org parser. They are used to overwrite the context files coming with the d1_index_processor jar file.
dataone.indexing.schema.org.httpcontext.path=${application.deployDir}/metacat-index/WEB-INF/classes/contexts/jsonldcontext_http.jsonld
dataone.indexing.schema.org.httpscontext.path=${application.deployDir}/metacat-index/WEB-INF/classes/contexts/jsonldcontext_https.jsonld
dataone.indexing.schema.org.httpListcontext.path=${application.deployDir}/metacat-index/WEB-INF/classes/contexts/jsonldcontext_http_list.jsonld


############# Annotator Section ###########################################
annotator.sharedSecret=710f4e8c-25ee-4fb0-88ae-ae98a9edd0ad
annotator.consumerKey=f780f3e398cf45cbb4e84ed9ec91622a
annotator.store.url=http://annotateit.org/api/search

############# SOLR Search Section ###########################################
#Embedded:
#solr.server.classname=org.apache.solr.client.solrj.embedded.EmbeddedSolrServer
#solr.homeDir=/var/metacat/solr-home
#solr.configFileName=solr.xml
#solr.collectionName=collection1
#solr.env.script.path=/etc/default/solr.in.sh
  
#HTTP (default):
solr.server.classname=org.apache.solr.client.solrj.impl.CommonsHttpSolrServer
solr.baseURL=http://localhost:8983/solr
#solr.adminUser=
#solr.password=
solr.coreName=metacat-index
solr.homeDir=/var/metacat/solr-home2
sorl.schema.urlappendix=/admin/file/?contentType=text/xml\;charset=utf-8&file=schema.xml
solr.config.urlappendix=/admin/file/?contentType=text/xml\;charset=utf-8&file=solrconfig.xml
solr.systeminfo.urlappendix=/admin/system
solr.env.script.path=/etc/default/solr.in.sh

solr.query.append.includeArchived.name=archived
solr.query.append.includeArchived.value=-archived:*fake

# Indicate if Metacat deletes the multipart temp file on program exit or immediately 
multipart.tempFile.deleteOnExit=false

############# Package Download Section ###########################################

# Names of files that we add to the downloads
package.download.file.readme=README.html
package.download.file.science-metadata=science-metadata.xml
package.download.file.resource-map=oai-ore.xml

# Prefixes for the artifact names
package.download.file.sysmeta-prepend=sysmeta-
package.download.file.sysmeta-extension=.xml
package.download.file.bag-extension=.zip

# Bag directories
package.download.bag.directory.metadata=metadata
package.download.bag.directory.sysmeta=sysmeta
package.download.bag.directory.data=data
