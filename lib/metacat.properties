# Properties file defining options for the MetaCatServlet.java servlet
#
# Matt Jones, Dan Higgins, Jivka Bojilova
# '$Id$'
#

######## Configuration utility section  ################

configutil.propertiesConfigured=false
configutil.authConfigured=false
configutil.skinsConfigured=true
configutil.databaseConfigured=false
configutil.geoserverConfigured=false
configutil.dataoneConfigured=false
configutil.ezidConfigured=bypassed

############### Server Values #################

server.name=localhost
server.httpPort=80
server.httpSSLPort=443

############### Application Values ############

## one of the few places where we use ANT tokens
application.metacatVersion=2.8.6
application.metacatReleaseInfo=-1
application.readOnlyMode=false 

application.deployDir=
## This is autodiscovered and populated by the config utility
application.context=
application.default-style=default
application.knbSiteURL=http://knb.ecoinformatics.org
application.backupDir=
application.datafilepath=/var/metacat/data
application.inlinedatafilepath=/var/metacat/inline-data
application.documentfilepath=/var/metacat/documents
application.expandedArchivePath=/var/metacat/expanded-archives
application.tempDir=/var/metacat/temporary
# the location of cgi scripts relative to the metacat context directory
application.cgiDir=/cgi-bin
#used for writing debug info into a anouther out file
application.writeDebugToFile=true
#output file name where debug info will written
# TODO SCW: these should be using the temp-dir property for their paths (change in code)
application.debugOutputFile=/tmp/metacat.debug
#delimitered text output file name where debug info will be written
application.delimiteredOutputFile=/tmp/metacat.debug.delimitered

############### Database Values ###############

database.connectionURI=jdbc:postgresql://localhost/metacat
database.user=
database.password=
database.type=
database.driver=
database.adapter=
database.scriptsuffix.postgres=postgres.sql
database.scriptsuffix.oracle=oracle.sql
database.scriptsuffix.sqlserver=sqlserver.sql
database.upgradeVersion.0.0.0=xmltables,loaddtdschema
database.upgradeVersion.1.2.0=upgrade-db-to-1.2
database.upgradeVersion.1.3.0=upgrade-db-to-1.3
database.upgradeVersion.1.4.0=upgrade-db-to-1.4
database.upgradeVersion.1.5.0=upgrade-db-to-1.5
database.upgradeVersion.1.6.0=upgrade-db-to-1.6
database.upgradeVersion.1.7.0=upgrade-db-to-1.7
database.upgradeVersion.1.8.0=upgrade-db-to-1.8
database.upgradeVersion.1.9.0=upgrade-db-to-1.9
database.upgradeVersion.1.9.1=upgrade-db-to-1.9.1
database.upgradeVersion.1.9.2=upgrade-db-to-1.9.2
database.upgradeVersion.1.9.3=upgrade-db-to-1.9.3
database.upgradeVersion.1.9.4=upgrade-db-to-1.9.4
database.upgradeVersion.1.9.5=upgrade-db-to-1.9.5
database.upgradeVersion.2.0.0=upgrade-db-to-2.0.0
database.upgradeVersion.2.0.1=upgrade-db-to-2.0.1
database.upgradeVersion.2.0.2=upgrade-db-to-2.0.2
database.upgradeVersion.2.0.3=upgrade-db-to-2.0.3
database.upgradeVersion.2.0.4=upgrade-db-to-2.0.4
database.upgradeVersion.2.0.5=upgrade-db-to-2.0.5
database.upgradeVersion.2.0.6=upgrade-db-to-2.0.6
database.upgradeVersion.2.0.7=upgrade-db-to-2.0.7
database.upgradeVersion.2.0.8=upgrade-db-to-2.0.8
database.upgradeVersion.2.1.0=upgrade-db-to-2.1.0
database.upgradeVersion.2.1.1=upgrade-db-to-2.1.1
database.upgradeVersion.2.2.0=upgrade-db-to-2.2.0
database.upgradeVersion.2.2.1=upgrade-db-to-2.2.1
database.upgradeVersion.2.3.0=upgrade-db-to-2.3.0
database.upgradeVersion.2.3.1=upgrade-db-to-2.3.1
database.upgradeVersion.2.4.0=upgrade-db-to-2.4.0
database.upgradeVersion.2.4.1=upgrade-db-to-2.4.1
database.upgradeVersion.2.4.2=upgrade-db-to-2.4.2
database.upgradeVersion.2.4.3=upgrade-db-to-2.4.3
database.upgradeVersion.2.5.0=upgrade-db-to-2.5.0
database.upgradeVersion.2.5.1=upgrade-db-to-2.5.1
database.upgradeVersion.2.6.0=upgrade-db-to-2.6.0
database.upgradeVersion.2.7.0=upgrade-db-to-2.7.0
database.upgradeVersion.2.7.1=upgrade-db-to-2.7.1
database.upgradeVersion.2.7.2=upgrade-db-to-2.7.2
database.upgradeVersion.2.8.0=upgrade-db-to-2.8.0
database.upgradeVersion.2.8.1=upgrade-db-to-2.8.1
database.upgradeVersion.2.8.2=upgrade-db-to-2.8.2
database.upgradeVersion.2.8.3=upgrade-db-to-2.8.3
database.upgradeVersion.2.8.4=upgrade-db-to-2.8.4
database.upgradeVersion.2.8.5=upgrade-db-to-2.8.5
database.upgradeVersion.2.8.6=upgrade-db-to-2.8.6
## for running java-based utilities
database.upgradeUtility.1.5.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade1_5_0
database.upgradeUtility.2.0.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_0_0
database.upgradeUtility.2.3.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_3_0
database.upgradeUtility.2.4.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_4_0
database.upgradeUtility.2.4.2=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_4_2
database.upgradeUtility.2.5.1=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_5_1
database.upgradeUtility.2.7.0=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_7_0
database.upgradeUtility.2.8.1=edu.ucsb.nceas.metacat.admin.upgrade.Upgrade2_8_1
database.initialConnections=5
database.incrementConnections=5
# be sure to increase SQL connection limits accordingly:
database.maximumConnections=200
database.maximumConnectionAge=120000
database.maximumConnectionTime=60000
database.maximumUsageNumber=100
database.connectionCountWarnLimit=15
database.numberOfIndexingThreads=5
database.indexingTimerTaskTime=604800000
database.indexingInitialDelay=3600000
database.maximumIndexDelay=5000
database.runDBConnectionRecycleThread=off
database.cycleTimeOfDBConnection=30000
database.queryignoredparams=enableediting,foo
database.usexmlindex=true
# used for the setting the size of resultset for applications like morpho
database.appResultsetSize=7000
# used for the setting the size of resultset for searches done using browsers
database.webResultsetSize=7000
# the value of xml_returnfield.usage_count should be more than this value
# for records to be entered into xml_queryresult. so if you want results for
# any combination of returnfields to be stored in xml_queryresult only when
# that combination has been requested 50 times, set this value to 50
database.xmlReturnfieldCount=0
# used for the setting the size of queryresult_string in queryresult table.
# the limit is 4000 for oracle
database.queryresultStringLength=500000
#the size of query result cache
database.queryresultCacheSize=500
#turn on or off the query result cache
database.queryCacheOn=true
#the time in milliseconds that an squery can run before metacat logs a warning
database.queryTimeWarnLimit=30000
#the time in milliseconds that an squery can run before metacat logs a warning
database.squeryTimeWarnLimit=30000


######## DB Query section              #######################################
dbquery.enabledEngines=pathquery;solr
#the time in milliseconds that a stylesheet transform can run before metacat logs a warning
dbquery.transformTimeWarnLimit=60000
#the time in milliseconds to get a document list before metacat logs a warning
dbquery.findDocListTimeWarnLimit=60000
#the time in milliseconds to get return values from queryresults table before metacat logs a warning
dbquery.findQueryResultsTimeWarnLimit=60000
#the time in milliseconds to run extended (index and node) queries before metacat logs a warning
dbquery.extendedQueryRunTimeWarnLimit=60000
#the time in milliseconds to store return fields before metacat logs a warning
dbquery.storeReturnFieldTimeWarnLimit=60000
#the time in milliseconds to totally process return fields before metacat logs a warning
dbquery.totalReturnFieldTimeWarnLimit=120000

######## Datamanager section              #######################################
datamanager.adapter=PostgresAdapter
datamanager.implementation=edu.ucsb.nceas.metacat.dataquery.PostgresDatabaseConnectionPool
datamanager.server=localhost
datamanager.database=datamanager
datamanager.user=datamanager
datamanager.password=datamanager
datamanager.maxconnections=10

#datamanager.endpoint.query=http://ecogrid.ecoinformatics.org/metacat/services/QueryService
#datamanager.endpoint.authenticatedquery=http://ecogrid.ecoinformatics.org/metacat/services/AuthenticatedQueryService
#datamanager.endpoint.authentication=http://ecogrid.ecoinformatics.org/metacat/services/AuthenticationService
#datamanager.endpoint.put=http://ecogrid.ecoinformatics.org/metacat/services/PutService
#datamanager.endpoint.identifier=http://ecogrid.ecoinformatics.org/metacat/services/IdentificationService
#datamanager.srb.endpoint=
#datamanager.srb.machinename=

######## Plugin section              #######################################
plugin.handlers=

######## Authentication  ##############################################

auth.class=edu.ucsb.nceas.metacat.authentication.AuthFile
#auth.class=edu.ucsb.nceas.metacat.AuthLdap
# Use AuthStub to test and guarantee authentication
#auth.class=edu.ucsb.nceas.metacat.AuthStub
#auth.administrators=uid=jones,o=NCEAS,dc=ecoinformatics,dc=org
auth.administrators=
auth.userManagementUrl=
auth.allowedSubmitters=
auth.deniedSubmitters=
auth.moderators=
#auth.moderators=cn=knb-prod,o=NCEAS,dc=ecoinformatics,dc=org
#auth.moderators=cn=knb-prod,o=NCEAS,dc=ecoinformatics,dc=org:cn=esa-moderators,dc=ecoinformatics,dc=org:cn=parc-moderators,o=PARC,dc=ecoinformatics,dc=org
auth.defaultUserManagementPage=/style/common/default-user-management.jsp
#####File-based Authentication######
auth.file.path=/var/metacat/users/password.xml
auth.file.hashClassName=edu.ucsb.nceas.metacat.authentication.AuthFileBCryptHash
######LDAP-based Authentication#############
auth.timeoutMinutes=180
auth.url=ldap://ldap.ecoinformatics.org:389/
auth.surl=ldap://ldap.ecoinformatics.org:389/
auth.base=dc=ecoinformatics,dc=org
# time in milliseconds allowed for ldap server connections
ldap.connectTimeLimit=5000
# time in milliseconds allowed for ldap server searches
ldap.searchTimeLimit=30000
# count of return entries allowed for ldap server searches
ldap.searchCountLimit=30000
ldap.referral=follow
ldap.onlySecureConnection=false
ldap.onlySecureReferalsConnection=false
ldap.server.ca.certificate=
ldap.nextuid.storing.dn=cn=uidNext,dc=ecoinformatics,dc=org
ldap.nextuid.storing.attributename=description
ldap.nextuid.maxattempt=300
ldap.recaptcha.publickey=yourPublicKey
ldap.recaptcha.privatekey=yourPrivateKey

# LDAP templates 
ldap.templates.stage=initregister
ldap.templates.header=genericHeader.tmpl
ldap.templates.footer=genericFooter.tmpl
ldap.templates.changePass=ldapChangePass.tmpl
ldap.templates.changePassSuccess=ldapChangePassSuccess.tmpl
ldap.templates.resetPass=ldapResetPass.tmpl
ldap.templates.resetPassSuccess=ldapResetPassSuccess.tmpl
ldap.templates.register=ldapRegister.tmpl
ldap.templates.registerFailed=ldapRegisterFailed.tmpl
ldap.templates.registerMatch=ldapRegisterMatch.tmpl
ldap.templates.registerSuccess=ldapRegisterSuccess.tmpl
ldap.templates.verificationSuccess=ldapVerificationSuccess.tmpl
ldap.templates.verificationFailed=ldapVerificationFailed.tmpl
ldap.templates.registerLter=ldapRegisterLter.tmpl
ldap.templates.success=ldapRegisterSuccess.tmpl
ldap.templates.failed=ldapRegisterFailed.tmpl
ldap.templates.mainServerFailure=ldapMainServerFailure.tmpl
ldap.templates.searchResults=searchResults.tmpl
ldap.templates.lookupName=ldapLookupName.tmpl
ldap.templates.lookupNameSuccess=ldapLookupNameSuccess.tmpl
#The property defines a default value which controls the list of organization names showing in the account registration, 
#password reset and change password templates for all skins.
#The value of the property will be overwritten if a skin properties file defines the property as well.
#The value of the property should be defined in the organization.name.VALUE=something in the organization part.
#Multiple values will be separated by ";".
ldap.templates.organizationList=unaffiliated

############### Session Values ###############
session.timeoutMinutes=360

############### Organization Values ###############
organization.configured.NCEAS=false
organization.name.NCEAS=National Center for Ecological Analysis and Synthesis
organization.label.NCEAS=NCEAS
organization.password.NCEAS=
organization.expiration.NCEAS=36
organization.configured.OBFS=false
organization.name.OBFS=Organization of Biological Field Stations
organization.configured.OSUSB=false
organization.name.OSUSB=
organization.configured.UCNRS=false
organization.name.UCNRS=University of California Natural Reserve System
organization.base.UCNRS=ou=people,o=ucnrs.org
organization.user.UCNRS=uid=nrsadmin,o=NCEAS,dc=ecoinformatics,dc=org
organization.password.UCNRS=
organization.configured.KU=false
organization.name.KU=
organization.configured.LTER=false
organization.name.LTER=
organization.configured.UVM=false
organization.name.UVM=
organization.configured.SDSC=false
organization.name.SDSC=
organization.configured.MSU=false
organization.name.MSU=
organization.configured.NAPIER=false
organization.name.NAPIER=
organization.configured.SANPARKS=false
organization.name.SANPARKS=Kruger National Park
organization.org.SANPARKS=o=SANPARKS
organization.configured.SAEON=false
organization.name.SAEON=South African Environmental Observation Network Repository
organization.org.SAEON=o=SAEON

organization.name.unaffiliated=unaffiliated
organization.base.unaffiliated=dc=ecoinformatics,dc=org
organization.org.unaffiliated=o=unaffiliated
organization.user.unaffiliated=cn=Manager
organization.password.unaffiliated=
organization.expiration.unaffiliated=36
organization.label.unaffiliated=KNB/AOOS


organization.name.Account=Account
organization.base.Account=dc=ecoinformatics,dc=org
organization.org.Account=ou=Account
organization.user.Account=cn=Manager
organization.password.Account=
organization.expiration.Account=36
organization.label.Account=NCEAS/DataONE/Kepler

######## XML / EML  #########################################

xml.saxparser=org.apache.xerces.parsers.SAXParser
xml.eml2_0_0namespace=eml://ecoinformatics.org/eml-2.0.0
xml.eml2_0_1namespace=eml://ecoinformatics.org/eml-2.0.1
xml.eml2_1_0namespace=eml://ecoinformatics.org/eml-2.1.0
xml.eml2_1_1namespace=eml://ecoinformatics.org/eml-2.1.1
xml.rdf_syntax_namespace=http://www.w3.org/1999/02/22-rdf-syntax-ns#
xml.useFullSchemaValidation=true
xml.packagedoctype=-//ecoinformatics.org//eml-dataset-2.0.0beta6//EN, -//ecoinformatics.org//eml-dataset-2.0.0beta4//EN
xml.accessdoctype=-//ecoinformatics.org//eml-access-2.0.0beta6//EN, -//ecoinformatics.org//eml-access-2.0.0beta4//EN
xml.physicaldoctype=-//ecoinformatics.org//eml-physical-2.0.0beta6//EN, -//ecoinformatics.org//eml-physical-2.0.0beta4//EN
xml.entitydoctype=-//ecoinformatics.org//eml-entity-2.0.0beta6//EN, -//ecoinformatics.org//eml-entity-2.0.0beta4//EN
xml.packagedoctypeset=BIN,-//ecoinformatics.org//eml-access-2.0.0beta6//EN,-//ecoinformatics.org//eml-access-2.0.0beta4//EN,-//ecoinformatics.org//eml-attribute-2.0.0beta6//EN,-//ecoinformatics.org//eml-attribute-2.0.0beta4//EN,-//ecoinformatics.org//eml-constraint-2.0.0beta6//EN,-//ecoinformatics.org//eml-constraint-2.0.0beta4//EN,-//ecoinformatics.org//eml-coverage-2.0.0beta6//EN,-//ecoinformatics.org//eml-coverage-2.0.0beta4//EN,-//ecoinformatics.org//eml-dataset-2.0.0beta6//EN,-//ecoinformatics.org//eml-dataset-2.0.0beta4//EN,-//ecoinformatics.org//eml-entity-2.0.0beta6//EN,-//ecoinformatics.org//eml-entity-2.0.0beta4//EN,-//ecoinformatics.org//eml-literature-2.0.0beta6//EN,-//ecoinformatics.org//eml-literature-2.0.0beta4//EN,-//ecoinformatics.org//eml-physical-2.0.0beta6//EN,-//ecoinformatics.org//eml-physical-2.0.0beta4//EN,-//ecoinformatics.org//eml-project-2.0.0beta6//EN,-//ecoinformatics.org//eml-project-2.0.0beta4//EN,-//ecoinformatics.org//eml-protocol-2.0.0beta6//EN,-//ecoinformatics.org//eml-protocol-2.0.0beta4//EN,-//ecoinformatics.org//eml-software-2.0.0beta6//EN,-//ecoinformatics.org//eml-software-2.0.0beta4//EN
xml.indexNamespaces=eml://ecoinformatics.org/eml-2.0.0,eml://ecoinformatics.org/eml-2.0.1,eml://ecoinformatics.org/eml-2.1.0,eml://ecoinformatics.org/eml-2.1.1,http://www.kepler-project.org/kar-2.0.0,http://www.kepler-project.org/kar-2.1.0
xml.indexPaths=                            \
	@packageId,                            \
	/reviewHistory/review/packageId,       \
	abstract,                              \
	abstract/value,                        \
	abstract/para,                         \
	abstract/para/value,                   \
	access/allow/principal,                \
	additionalMetadata/metadata/spatialResolution/value,	\
	additionalMetadata/metadata/spatialResolution/units,	\
	additionalMetadata/moderatorComment,   \
	associatedParty/individualName/surName,                           \
	associatedParty/organizationName,                                 \
	coverage/temporalCoverage/rangeOfDates/beginDate/alternativeTimeScale/timeScaleName,   \
	coverage/temporalCoverage/rangeOfDates/endDate/alternativeTimeScale/timeScaleName,     \
	coverage/temporalCoverage/singleDateTime/alternativeTimeScale/timeScaleName,           \
	coverage/temporalCoverage/rangeOfDates/beginDate/calendarDate,   \
	coverage/temporalCoverage/rangeOfDates/endDate/calendarDate,     \
	coverage/temporalCoverage/singleDateTime/calendarDate,           \	
	coverage/temporalCoverage/rangeOfDates/beginDate/time,   \
	coverage/temporalCoverage/rangeOfDates/endDate/time,     \
	coverage/temporalCoverage/singleDateTime/time,           \		
	creator/individualName/surName,        \
	creator/individualName/givenName,      \
	creator/organizationName,              \
	dataset/access/allow/principal,        \
	dataset/dataTable/physical/distribution/online/url,               \
	dataset/dataTable/physical/distribution/online/url/@function,     \
	dataset/spatialRaster/physical/distribution/online/url,           \
	dataset/spatialRaster/physical/distribution/online/url/@function, \
	dataset/otherEntity/physical/distribution/online/url,           \
	dataset/otherEntity/physical/distribution/online/url/@function, \
	physical/encodingMethod, \
	dataset/title,                         \
	dataset/title/value,                   \
	eastBoundingCoordinate,                \
	eastbc,                                \
	EcogridRegEntry/description,           \
	EcogridRegEntry/endPoint,              \
	EcogridRegEntry/serviceName,           \
	entityName,                            \
	geographicCoverage/boundingCoordinates/eastBoundingCoordinate,    \
	geographicCoverage/boundingCoordinates/northBoundingCoordinate,   \
	geographicCoverage/boundingCoordinates/southBoundingCoordinate,   \
	geographicCoverage/boundingCoordinates/westBoundingCoordinate,    \
	geographicDescription,                 \
	givenName,                             \
	idinfo/citation/citeinfo/title,        \
	idinfo/citation/citeinfo/origin,       \
	idinfo/keywords/theme/themekey,        \
	individualName/surName,                \
	keyword,                               \
	karEntry/karEntryAttributes/type,      \
	karEntry/karEntryXML/property/property/@name,           \
	karEntry/karEntryXML/property/property/@value,          \
	karEntry/karEntryXML/property/property/property/@name,  \
	karEntry/karEntryXML/property/property/property/@value, \
	karFileName,                           \
	karFileSize,                           \
	keyword/value,                         \
	literalLayout,                         \
	mainAttributes/lsid,                   \
	northbc,                               \
	northBoundingCoordinate,               \
	organizationName,                      \
	originator/individualName/surName,     \
	originator/individualName/givenName,   \
	originator/organizationName,           \
	para,                                  \
	placekey,                              \
	southBoundingCoordinate,               \
	southbc,                               \
	surName,                               \
	taxonomicClassification/taxonRankName,          \
	taxonomicClassification/taxonRankValue,         \
	taxonRankValue,                        \
	title,                                 \
	westBoundingCoordinate,                \
	westbc

######## Outgoing email  #########################################

email.mailhost=localhost
email.sender=knb-software@nceas.ucsb.edu
email.contact=knb-software@nceas.ucsb.edu
email.admin=KNB Support
email.recipient=knb-software@nceas.ucsb.edu

######## Replication properties  #########################################

replication.logdir=
## deltaT=60
## debuglevel=55
replication.datafileflag=datafile
## TODO MCD this seems to be used in other placed besides replication
replication.datafilesizelimit=1000
replication.defaultcontenttype=application/octet-stream
replication.timedreplication=false
replication.firsttimedreplication=10:00 PM
replication.timedreplicationinterval=172800000
replication.forcereplicationwaitingtime=30000
replication.client.timeout=60000
# certificate-based replication configuration
replication.certificate.file=/etc/dataone/client/certs/METACAT1.pem
replication.privatekey.file=/etc/dataone/client/certs/METACAT1.pem
replication.privatekey.password=


######## Skins  #########################################

skin.names=default,metacatui,nceas,esa,knb,kepler,lter,ltss,obfs,nrs,sanparks,saeon,first,parc,dataone

############# UI Section ###########################################
ui.context=metacatui

######## Document Section  #########################################

#The flag to indicate if invalidated eml 201 documents were corrected.
#Before Metacat 1.8.1, metacat uses tag RELEASE_EML_2_0_1_UPDATE_6 as eml
#schema, which accidentily points to wrong version of eml-resource.xsd.
#If this value is false, metacat will run a class to correct eml201 doucment.
document.eml201DocumentCorrected=true
document.sitecode=nceas
document.accNumSeparator=.
document.accNumPrefix=autogen

######## Harvester section            #########################################

harvester.connectToMetacat=true
harvester.delay=0
harvester.administrator=name@institution.edu
harvester.logPeriod=90
harvester.maxHarvests=0
harvester.period=24
harvester.smtpServer=localhost
harvester.GetDocError=Error getting EML document from site,Error
harvester.GetDocSuccess=Success getting EML document from site,Debug
harvester.GetHarvestListError=Error getting harvest list from site,Error
harvester.GetHarvestListSuccess=Success getting harvest list from site,Debug
harvester.HarvesterStartup=Harvester start up,Info
harvester.HarvesterShutdown=Harvester shut down,Info
harvester.InsertDocError=Error inserting EML document to Metacat,Error
harvester.InsertDocSuccess=Success inserting EML document to Metacat,Info
harvester.MetacatHasDoc=Metacat already has this EML document,Info
harvester.UpdateDocError=Error updating EML document to Metacat,Error
harvester.UpdateDocSuccess=Success updating EML document to Metacat,Info
harvester.ValidateDocError=Error validating EML docoument,Error
harvester.ValidateDocSuccess=Success validating EML document,Debug
harvester.ValidateHarvestListError=Error validating harvest list,Error
harvester.ValidateHarvestListSuccess=Success validating harvest list,Debug

######## OAI-PMH section              #######################################

oaipmh.maxListSize=5
oaipmh.repositoryIdentifier=localhost:8080
AbstractCatalog.oaiCatalogClassName=edu.ucsb.nceas.metacat.oaipmh.provider.server.catalog.MetacatCatalog
AbstractCatalog.recordFactoryClassName=edu.ucsb.nceas.metacat.oaipmh.provider.server.catalog.MetacatRecordFactory
# Duration of resumption tokens
AbstractCatalog.secondsToLive=3600
# Choose one of the following two
AbstractCatalog.granularity=YYYY-MM-DD
#AbstractCatalog.granularity=YYYY-MM-DDThh:mm:ssZ
# Custom Identify response values
Identify.repositoryName=Local Metacat OAI-PMH Data Provider
Identify.adminEmail=mailto:admin@localhost
Identify.earliestDatestamp=2000-01-01T00:00:00Z
Identify.deletedRecord=no
# Append something unique like .1, .2, etc to 'Identify.description' for each occurrence
#Identify.description.1=<description><oai-identifier xmlns\="http\://www.openarchives.org/OAI/2.0/oai-identifier" xmlns\:xsi\="http\://www.w3.org/2001/XMLSchema-instance" xsi\:schemaLocation\="http\://www.openarchives.org/OAI/2.0/oai-identifier http\://www.openarchives.org/OAI/2.0/oai-identifier.xsd"><scheme>oai</scheme><repositoryIdentifier>metacat.lternet.edu</repositoryIdentifier><delimiter>\:</delimiter><sampleIdentifier>http\://metacat.lternet.edu/metacat/metacat/knb-lter-lno.1</sampleIdentifier></oai-identifier></description>
# List the supported metadataPrefixes along with the class that performs the associated crosswalk
Crosswalks.oai_dc=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml2oai_dc
Crosswalks.eml-2.0.0=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml200
Crosswalks.eml-2.0.1=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml201
Crosswalks.eml-2.1.0=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml210
Crosswalks.eml-2.1.1=edu.ucsb.nceas.metacat.oaipmh.provider.server.crosswalk.Eml211

######## Spatial section              #########################################

spatial.runSpatialOption=true
spatial.regenerateCacheOnRestart=true
# Comma-seperated list of schemas containing spatial bounding boxes
# name corresponds to the docname stored in xml_documents table
spatial.spatialDocnameList=eml,fgdc,metadata
# XML paths to the four bounding coordinates
# These paths must be included in your indexPaths variable in build.properties
# Note the naming convention:
#   {docname}_{direction}BoundingCoordinatePath=.....
# Has not been tested with other schemas besides EML
spatial.eml_westBoundingCoordinatePath=geographicCoverage/boundingCoordinates/westBoundingCoordinate
spatial.eml_eastBoundingCoordinatePath=geographicCoverage/boundingCoordinates/eastBoundingCoordinate
spatial.eml_southBoundingCoordinatePath=geographicCoverage/boundingCoordinates/southBoundingCoordinate
spatial.eml_northBoundingCoordinatePath=geographicCoverage/boundingCoordinates/northBoundingCoordinate
spatial.fgdc_westBoundingCoordinatePath=spdom/bounding/westbc
spatial.fgdc_eastBoundingCoordinatePath=spdom/bounding/eastbc
spatial.fgdc_southBoundingCoordinatePath=spdom/bounding/southbc
spatial.fgdc_northBoundingCoordinatePath=spdom/bounding/northbc
spatial.metadata_westBoundingCoordinatePath=westbc
spatial.metadata_eastBoundingCoordinatePath=eastbc
spatial.metadata_southBoundingCoordinatePath=southbc
spatial.metadata_northBoundingCoordinatePath=northbc
spatial.docTitle=dataset/title

######## Geoserver section              #######################################

geoserver.username=admin
geoserver.password=geoserver
geoserver.context=geoserver
geoserver.GEOSERVER_DATA_DIR=


######## workflowScheduler section              #######################################

workflowScheduler.url=http://localhost/workflowscheduler/scheduler
workflowScheduler.authorizationPath=/services/AuthorizationService
workflowScheduler.authenticationPath=/services/AuthenticationService
workflowScheduler.queryPath=/services/QueryService

######## SiteMap section              #########################################

# relative directory path in which sitemap files should be written
## sitemapDirectory=@install-dir@/sitemaps

# Interval (in milliseconds) between rebuilding the sitemap
sitemap.interval=86400000
sitemap.excludedata=false

######## Workflow engine section              #########################################
executionEngine.workflowRunEngineName=localWorkflowEngine
executionEngine.endPointAddress=http://localhost/workflowrunengine/services/KeplerWebService
executionEngine.resultDestinationRepository=sanparksRepository:keplerRepository:keplerDevRepository:chico1Repository
######## junit test section  ################

test.printdebug=true
test.metacatUrl=http://localhost:8080/metacat/metacat
test.contextUrl=http://localhost:8080/metacat
test.workflowSchedulerUrl=http://localhost:8080/workflowscheduler/scheduler
test.metacatDeployDir=/opt/local/share/java/tomcat7/webapps/metacat
test.mcUser=uid=kepler,o=unaffiliated,dc=ecoinformatics,dc=org
test.mcPassword=kepler
test.mcAnotherUser=uid=test,o=NCEAS,dc=ecoinformatics,dc=org
test.mcAnotherPassword=test
test.referralUser=uid=testreferral,o=UCNRS,dc=ecoinformatics,dc=org
test.referralPassword=testreferral
test.lterUser=uid=knbuser,o=LTER,dc=ecoinformatics,dc=org
test.lterPassword=b1gf1$h
test.piscoUser=uid=piscotest,o=PISCO,dc=ecoinformatics,dc=org
test.piscoPassword=testPW
test.testProperty=testing
test.replication.targetServer=mn-demo-6.test.dataone.org/knb
test.dataone.replication.sourceNodeId=urn:node:mnSandboxUCSB1
test.dataone.replication.waitingTime=5000
#test.dataone.replication.waitingTime=480000

######## Developers Section #########################################

# Set dev.runConfiguration to false to keep the system from walking you 
# through the configuration utility every time you reinstall metacat.  
# Instead,  the system will use backed up configuration values.  If you 
# haven't ever configured the app (no backup files) the system will take 
# you through the configuration.
dev.runConfiguration=true


############# DataONE Section #######################################
D1Client.CN_URL=https://cn.dataone.org/cn
# Configure the Member Node client certificate location
D1Client.certificate.file=/var/metacat/certs/METACAT1.pem
# Client resources
D1Client.resourcesDir=/var/metacat/dataone
# Member Node configuration
dataone.nodeId=urn:node:METACAT_TEST
dataone.subject=CN=urn:node:METACAT1,DC=dataone,DC=org
dataone.contactSubject=CN=Scientist 1234,DC=dataone,DC=org
dataone.nodeName=My Metacat Node
dataone.nodeType=mn
dataone.nodeDescription=Describe your Member Node briefly.
dataone.nodeSynchronize=false
dataone.nodeReplicate=false
dataone.serviceName=d1

# the synchronization schedule
dataone.nodeSynchronization.schedule.year=*
dataone.nodeSynchronization.schedule.mon=*
dataone.nodeSynchronization.schedule.mday=*
dataone.nodeSynchronization.schedule.wday=?
dataone.nodeSynchronization.schedule.hour=*
dataone.nodeSynchronization.schedule.min=0/3
dataone.nodeSynchronization.schedule.sec=10

# The default replication policy
dataone.replicationpolicy.default.numreplicas=0
dataone.replicationpolicy.default.preferredNodeList=
dataone.replicationpolicy.default.blockedNodeList=

# Default checksum algorithm
dataone.checksumAlgorithm.default=MD5

# Default file upload size for create() and update (in bytes, or -1 for no limit)
# Note that this is parsed as an int value, so must be < 2^31-1
dataone.max_upload_size=1000000000

# overall services (TODO: mn vs. cn?)
dataone.mn.services.enabled=true
dataone.mn.registration.submitted=false

# state which versions of each MN tier service are availalble
dataone.mnCore.serviceAvailable=true;true
dataone.mnCore.serviceVersion=v1;v2
dataone.mnRead.serviceAvailable=true;true                                                                                                                                                                                                                                                             
dataone.mnRead.serviceVersion=v1;v2
dataone.mnAuthorization.serviceAvailable=true;true
dataone.mnAuthorization.serviceVersion=v1;v2
dataone.mnStorage.serviceAvailable=true;true
dataone.mnStorage.serviceVersion=v1;v2
dataone.mnReplication.serviceAvailable=true;true
dataone.mnReplication.serviceVersion=v1;v2
dataone.mnPackage.serviceAvailable=true;true
dataone.mnPackage.serviceVersion=v1;v2
dataone.mnView.serviceAvailable=true
dataone.mnView.serviceVersion=v2

# The DataONE storage cluster configuration for Hazelcast
#dataone.hazelcast.configFilePath=/etc/dataone/storage/hazelcast.xml
dataone.hazelcast.storageCluster.systemMetadataMap=hzSystemMetadata
dataone.hazelcast.storageCluster.objectPathMap=hzObjectPath
dataone.hazelcast.storageCluster.identifiersSet=hzIdentifiers
dataone.hazelcast.storageCluster.tasksIdNamespace=task-ids

# Parameters for connecting to the DataONE process cluster as a Hazelcast client
dataone.hazelcast.processCluster.groupName=dev
dataone.hazelcast.processCluster.password=dataone
dataone.hazelcast.processCluster.instances=127.0.0.1
dataone.hazelcast.processCluster.nodesMap=hzNodes

# DataONE types XSLT
dataone.types.xsl.v1=/cn/xslt/dataone.types.v1.xsl
dataone.types.xsl.v2=/cn/xslt/dataone.types.v2.xsl


# DataONE configuration settings
dataone.ore.downloaddata=false
dataone.ore.generated=false
dataone.systemmetadata.generated=false


# DataONE http client settings
# increased from 5
D1Client.http.maxConnectionsPerServer=50

# increased from 200
D1Client.http.maxConnectionsTotal=500


############# Global Identifiers Assignment Section ######################
guid.assignGUIDs=false
guid.ezid.enabled=false
guid.ezid.username=apitest
guid.ezid.password=
guid.ezid.baseurl=https://ezid.cdlib.org/
#guid.ezid.baseurl=https://n2t.net/ezid/
# optional path for target. do not include hostname here. <IDENTIFIER> is replaced with real value
guid.ezid.uritemplate.metadata=/metacatui/#view/<IDENTIFIER>
#guid.ezid.uritemplate.data=
guid.ezid.doishoulder.1=doi:10.5072/FK2
#guid.ezid.doishoulder.1=doi:10.5072/FK2/KNB/
#guid.ezid.doishoulder.3=doi:10.5072/FK2/PISCO/
#guid.ezid.doishoulder.6=doi:10.5072/FK2/LTER/

############# Index Section ###########################################
#The md5 hash numbers for the schema.xml in previous releases. It should be sperator by ';' if it has multiple values.
index.schema.previous.hash=714457a3cdd05e034e5df46589b3bfa9;ba7dc67bbf749b02e03d7b7cc6a31def;ebf5b20f9cd18d31c3a6057749ba9397;fb1f63a36f2c742f1ba144d559c37075;2acacecbb55721806b7e92d7a115c35a;3418ed9d10bbc70f1e8020233d954f83;a54e667426384f89106405263df77373;8fc703ec01ef6d4cb413d9c2fbced532
#The md5 hash number for the schema.xml in this release
index.schema.current.hash=8fc703ec01ef6d4cb413d9c2fbced532
index.context=metacat-index
index.resourcemap.namespace=http://www.w3.org/TR/rdf-syntax-grammar;http://www.openarchives.org/ore/terms
#The process to regenerate the index when the metacat-index web app starts needs the readiness of the metacat.
#The index.regenerate.start.waitingtime (in milliseconds) and index.regenerate.start.maxattempts are used to control the waiting time. 
index.regenerate.start.waitingtime=10000
index.regenerate.start.maxattempts=600
#An interval to run the thread to regenerate solr index which failed before.
#If the inerval is less than 0, the thread would not run.
index.regenerate.interval=43200000
index.eventlog.classname=edu.ucsb.nceas.metacat.index.event.HazelcastIndexEventLog
index.hazelcast.indexqueue=hzIndexQueue
index.hazelcast.indexeventmap=hzIndexEventMap
index.tdb.directory=/var/metacat/tdb

############# Annotator Section ###########################################
annotator.sharedSecret=710f4e8c-25ee-4fb0-88ae-ae98a9edd0ad
annotator.consumerKey=f780f3e398cf45cbb4e84ed9ec91622a
annotator.store.url=http://annotateit.org/api/search

############# SOLR Search Section ###########################################
#Embedded (default):
solr.server.classname=org.apache.solr.client.solrj.embedded.EmbeddedSolrServer
solr.homeDir=/var/metacat/solr-home
solr.configFileName=solr.xml
solr.collectionName=collection1
  
#HTTP:
#solr.server.classname=org.apache.solr.client.solrj.impl.CommonsHttpSolrServer
#solr.endpoint=http://localhost:8080/solr/
#sorl.schema.urlappendix=/admin/file/?contentType=text/xml;charset=utf-8&file=schema.xml
#solr.config.urlappendix=/admin/file/?contentType=text/xml;charset=utf-8&file=solrconfig.xml
#solr.systeminfo.urlappendix=/admin/system
#Solr-home for the http solr server is used to store some files. It can be not really solr home.
#solr.homeDir=/var/metacat/solr-home

