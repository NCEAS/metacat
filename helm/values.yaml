## Default values for metacat.
## This is a YAML-formatted file.

## @section Metacat Application-Specific Properties
##
## The metacat section can contain any properties that metacat would expect to find in its
## configuration. These will be mounted in the container as metacat-site.properties,
## and will override the corresponding values in metacat.properties.
## The properties that have been pre-populated in this section comprise the minimum set of
## values needed to run the app and the test suite on a development machine.
##
## NOTE that certain credentials must also be provided, via Kubernetes Secrets, in order for
## metacat to function correctly. These credentials are listed in ./admin/secrets.yaml, in the
## form of environment variables expected by metacat at runtime. Also see the mappings in the
## `application.envSecretKeys` property in `metacat.properties`, to determine which metacat
## property corresponds to each of these environment variables
##
metacat:
  ## @param metacat.application.context The application context to use
  ## - for example, if your application is hosted at
  ## https://mydomain.org, and you define the context to be "metacat", then the url to access the
  ## application will be https://mydomain.org/metacat/
  ## NOTE: if changing this value, ensure the following paths are also updated to match:
  ##   readinessProbe.httpGet.path; livenessProbe.httpGet.path; ingress.hosts.paths
  ##
  application.context: metacat

  ## @param metacat.administrator.username The admin username that will be used to authenticate
  ## with the new metacat instance and apply any necessary setup steps, database upgrades etc.
  ## upon first run.
  ## NOTES:
  ## 1. The corresponding password must be set as a Secret (see ./admin/secrets.yaml), with the
  ##    key METACAT_ADMINISTRATOR_PASSWORD
  ## 2. This account will be created if it doesn't already exist in the `passwords.xml` file on
  ##    metacat's mounted PersistentVolume (see .Values.persistence)
  ## 3. This username MUST appear on the list of authorized administrators, otherwise
  ##    container startup will fail (see @param auth.administrators)
  ##
  administrator.username: admin@localhost

  ## @param metacat.auth.administrators A colon-separated list of admin usernames or LDAP-style DN
  ## (Distinguished Names) denoting the users who may log into metacat with administrator
  ## privileges.
  ##
  auth.administrators: admin@localhost:uid=jones,o=NCEAS,dc=ecoinformatics,dc=org

  ## @param metacat.database.connectionURI Connection URI for the postgres database
  ## in the form: jdbc:postgresql://hostname/database-name
  ## NOTE: ensure the `database-name` matches the value of `postgresql.auth.database`
  ## If you are connecting to a dev instance running on localhost, use:
  ##     database.connectionURI: jdbc:postgresql://host.docker.internal/metacat
  ## To connect to another k8s instance, use:
  ##     <servicename>.<namespace>.svc.cluster.local
  ## To connect to the instance deployed by the sub-chart, we simply use the name of the database
  ## k8s service (without the <namespace>.svc.cluster.local, since this is specified in the 'search'
  ## list in /etc/resolv.conf)
  ##
  database.connectionURI: jdbc:postgresql://mc-postgresql/metacat

  ## @param metacat.guid.doi.enabled Allow users to publish Digital Object Identifiers at doi.org?
  ## If true, you will also need to define guid.doi.username $ guid.doi.password (see secrets.yaml)
  ## and either override or use the defaults in metacat.properties for all the entries that begin
  ## with: "guid.doi."
  ##
  guid.doi.enabled: true

  ## @param metacat.server.httpPort The http port exposed internally by the metacat container
  ## 
  server.httpPort: 8080

  ## @param metacat.server.name The hostname for the server, as exposed by the ingress
  ## and seen by end users outside the cluster
  server.name: &external-hostname localhost

  ## @param metacat.solr.baseURL The url to access solr
  ## host.docker.internal is equivalent to "localhost"
  ##
  solr.baseURL: http://host.docker.internal:8983/solr

  ## @param metacat.replication.logdir Location for the replication logs
  ##
  replication.logdir: /var/metacat/logs

## @section Metacat Image, Container & Pod Parameters
##

## @param image.repository Metacat image repository
## @param image.tag Metacat image tag (immutable tags are recommended)
## @param image.pullPolicy Metacat image pull policy
image:
  #TODO pull from github container repo, e.g. see indexer: ghcr.io/dataoneorg/dataone-index-worker
  repository: metacat
  pullPolicy: IfNotPresent

  ## @param image.tag Overrides the image tag. Will default to the chart appVersion if set to ""
  ##
  tag: "DEVELOP"

  ## @param image.debug Specify if container debugging should be enabled (sets log level to "DEBUG")
  ## Set to true if you would like to see extra information in metacat/tomcat logs.
  ## * * WARNING - FOR TESTING ONLY! * * May result in secrets being printed to logs in plain text.
  ##
  debug: false

## @param imagePullSecrets [array] Optional list of references to secrets in the same namespace
## to use for pulling any of the images used by this chart
imagePullSecrets: []

## ServiceAccount
## @param serviceAccount.create Should a service account be created to run Metacat?
## @param serviceAccount.annotations Annotations to add to the service account
## @param serviceAccount.name The name to use for the service account.
##                  If not set and create is true, a name is generated using the fullname template
##
serviceAccount:
  create: false
  annotations: {}
  name: ""

## @param podAnnotations Map of annotations to add to the pods
##
podAnnotations: {}

## PodSecurityContext
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
## @param podSecurityContext.enabled Enable security context
## @param podSecurityContext.fsGroup Group ID for the pod
##
podSecurityContext:
  enabled: false
  fsGroup:

## @param securityContext Holds pod-level security attributes and common container settings
securityContext: {}    #TODO
##  fsGroup: metacat
##  runAsUser: metacat
##  capabilities:
##    readOnlyRootFilesystem: true
##    runAsNonRoot: true
##   drop:
##   - ALL

## @param resources Resource limits for the deployment
##  We usually recommend not to specify default resources and to leave this as a conscious
## choice for the user. This also increases chances charts run on environments with limited
## resources, such as Minikube.
resources: {}

## @param tolerations Tolerations for pod assigment
tolerations: []

## @section Metacat Persistence
##
persistence:
  ## @param persistence.enabled Enable metacat data persistence using Persistent Volume Claims
  ## Always set to 'enabled: true' for production deployments.
  ##
  ## For development/testing ONLY: Setting 'enabled: false' will result in the use of a temporary
  ## 'emptyDir' for saving metacat's data. This means the data saved by metacat WILL BE LOST when
  ## the pod is deleted!
  ##
  enabled: true

  ## @param persistence.storageClass Storage class of backing PV
  ##
  ## If <storageClass> is defined,  storageClassName: <storageClass>
  ##
  ## If <storageClass> set to "-",  storageClassName: ""  -- which disables dynamic PV provisioning
  ##   (meaning claim can only be bound to an existing PV, not a dynamically-provisioned one) with
  ##   no class (no annotation, or one set equal to "")
  ##
  ## NOTE when using StatefulSet with a defaultClaimTemplate - leaving storageClass unset/null does
  ## NOT choose the default provisioner for dynamic provisioning of the underlying PV, as expected!
  ## Instead, inspect your cluster to see what storageClass is set as default:
  ##    $  kubectl get storageclass
  ## ...and then explicitly set storageClass to match the name of the default storageclass
  ## (e.g. for Rancher Desktop, use:   storageclass: local-path)
  ##
  storageClass: local-path

  ## @param persistence.existingClaim Name of an existing Persistent Volume Claim to re-use
  ## Set a value for 'existingClaim' only if you want to re-use a Persistent Volume Claim that has
  ## already been set up by a k8s admin ahead of time.
  ## Leaving it blank will cause a pvc to be created dynamically using volumeClaimTemplates.
  ##
  existingClaim: ""

  ## @param persistence.accessModes PVC Access Mode for metacat volume
  ## Example:
  ##    accessModes:
  ##    - ReadWriteOnce   # allow only one node to mount in read/write mode
  ##    - ReadOnlyMany    # allow many nodes to mount in read-only mode
  ## ReadWriteOnce  is always required by metacat. ReadOnlyMany is useful for giving other
  ## services (e.g. metadig) read-only access to metacat data.
  ## Note that the underlying PersistentVolume (or pv auto-provisioner) must be able to provide
  ## these modes, in order for the PVC to bind successfully. (For Rancher Desktop, this means
  ## setting only ReadWriteOnce, not ReadOnlyMany)
  ##
  accessModes:
    - ReadWriteOnce

  ## @param persistence.size PVC Storage Request for metacat volume
  ##
  size: 1Gi

## @section Networking & Monitoring
##

## Ingress is a collection of rules that allow inbound connections to reach the endpoints defined
## by a backend. An Ingress can be configured to give services externally-reachable urls, load
## balance traffic, terminate SSL, offer name based virtual hosting etc.
##
ingress:
  ## @param ingress.enabled Enable or disable the ingress
  ##
  enabled: true

  ## @param ingress.className ClassName of the ingress provider in your cluster
  ##  Inspect available classes in your cluster using:    $ kc get ingressclasses
  ## For Rancher Desktop,  className: "traefik" (provided you have traefik enabled: 'preferences'->
  ## 'kubernetes'->'enable traefik')
  ##
  className: "traefik"

  ## @param ingress.hosts [array] A collection of rules mapping different hosts to the backend.
  ##        host: The external hostname exposed by the ingress and seen by clients,
  ##              that is mapped to this ingress via DNS
  ##        paths: A collection of rules mapping different paths on this host
  ##              to the backend. For each host, provide mappings to match incoming request paths:
  ##              path:     the url path used to identify the mapping
  ##              pathType: determines the interpretation of the Path-matching:
  ##                        Exact: Matches the URL path exactly.
  ##                        Prefix: Requires URL to begin with the pattern, not including substrings
  ##                        (e.g. /foo/bar matches /foo/bar/baz, but does not match /foo/barbaz).
  ##
  ## NOTE:   All paths will be mapped to the 'service.ports' entry with 'name: metacat-svc-web'
  ##
  hosts:
    - host: *external-hostname
      paths:
        - path: "/metacat"
          pathType: Prefix
        # remove the following if you do NOT want metacatui to be exposed & accessed via /metacatui
        # (default knb skin)
        - path: "/metacatui"
          pathType: Prefix

  ## @param ingress.annotations Annotations for the ingress
  ####  example: ####
  ##  annotations:
  ##    nginx.ingress.kubernetes.io/enable-cors: "true"
  ##    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, OPTIONS"
  ##    nginx.ingress.kubernetes.io/cors-allow-origin: '$http_origin'
  ##    nginx.ingress.kubernetes.io/cors-allow-credentials: "true"
  ##    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  ##
  annotations: {}

  ## @param ingress.tls The TLS configuration
  #### example ###
  ##  tls:
  ##    - hosts:
  ##        - api.test.dataone.org
  ##      secretName: ingress-nginx-tls-cert
  tls: []

## Headless ClusterIP required for StatefulSet
service:
  ## @param service.type Kubernetes Service type
  ##
  type: ClusterIP

  ## @param service.ports [array] The port(s) to be exposed
  ##        service.ports.port The port to expose
  ##        service.ports.name A unique name to identify this port.
  ##        Note that the ingress will direct metacat traffic to the port named "metacat-svc-web"
  ##
  ports:
    - port: 8080
      name: metacat-svc-web

## LivenessProbe
## Periodic probe of container liveness. Container will be restarted if the probe fails.
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
##
## @param livenessProbe.enabled Enable livenessProbe for Metacat container
## @param livenessProbe.httpGet.path The url path to probe.
##                Note that the context (first path element) must match the
##                value of metacat.application.context
## @param livenessProbe.httpGet.port The named containerPort to probe
##                as defined in ./templates/statefulset.yaml
## Optional values:
##        livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
##        livenessProbe.periodSeconds Period seconds for livenessProbe
##        livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
##        livenessProbe.failureThreshold Failure threshold for livenessProbe
##        livenessProbe.successThreshold Success threshold for livenessProbe
##
##
livenessProbe:    ## TODO - refine and/or create new lightweight healthcheck route
  enabled: true
  httpGet:
    path: /metacat/
    port: metacat-web

## ReadinessProbe
## Periodic probe of container service readiness. If the probe fails, container will be removed
## from service endpoints (but will not be restarted unless livenessProbe fails)
##
## @param readinessProbe.enabled Enable readinessProbe for Metacat container
## @param readinessProbe.httpGet.path The url path to probe.
##                Note that the context (first path element) must match the
##                value of metacat.application.context
## @param readinessProbe.httpGet.port The named containerPort to probe
##                as defined in ./templates/statefulset.yaml
## Optional values:
##        readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
##        readinessProbe.periodSeconds Period seconds for readinessProbe
##        readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
##        readinessProbe.failureThreshold Failure threshold for readinessProbe
##        readinessProbe.successThreshold Success threshold for readinessProbe
##
readinessProbe:    ## TODO - refine and/or create new lightweight healthcheck route
  enabled: true
  httpGet:
    path: /metacat/admin
    port: metacat-web

## @section Postgresql Sub-Chart
postgresql:
  ## @param postgresql.enabled enable the postgresql sub-chart
  ## set to false if you want to connect to your own existing postgresql deployment (and ensure
  ## metacat.database.connectionURI is set accordingly).
  ## Once the postgres container is running, test using:
  ##   $  kubectl exec -it <postgresql-pod-name> -- psql  -U <username>  -d <databasename>
  ## (or from a shell in metacat container: psql  -U <username>  -h <pghostname> <databasename>)
  ##
  enabled: true

  auth:
    ## @param postgresql.auth.username Username for accessing the database used by metacat
    ## For the corresponding password, see POSTGRES_PASSWORD in secrets.yaml
    ## (These values are also used by metacat to authenticate)
    ## NOTE: config in postgresql.primary.pgHbaConfiguration must allow the username defined here!
    ##
    username: metacat

    ## @param postgresql.auth.database The name of the database used by metacat.
    ## Make sure metacat.database.connectionURI is using this value
    ##
    database: metacat

    ## @param postgresql.auth.existingSecret Find the password in metacat's existing secrets
    ##
    existingSecret: mc-secrets

    ## @param postgresql.auth.secretKeys.userPasswordKey Identifies metacat db's account password
    ## within metacat's existing secrets
    ##
    secretKeys:
      userPasswordKey: POSTGRES_PASSWORD

      ## @param postgresql.auth.secretKeys.adminPasswordKey Dummy value - not used (see notes):
      ## Bitnami expects to find it in our 'existingSecret' secrets location, and fails otherwise
      ##
      adminPasswordKey: POSTGRES_PASSWORD

  ## @param postgresql.primary.pgHbaConfiguration PostgreSQL Primary client authentication
  ## configuration; ref: https://www.postgresql.org/docs/current/static/auth-pg-hba-conf.html
  ##
  primary:
    ## override the default pf_hba.conf with our own, to allow password auth, since this is the
    ## only method metacat currently supports (as of June 2023)
    pgHbaConfiguration: |
      host        metacat       metacat       0.0.0.0/0       password
      host        metacat       metacat       ::0/0           password
      local       all           all                           trust

    ## Postgresql persistence
    ## For explanatory notes, see top-level `persistence` section
    ## @param postgresql.primary.persistence.enabled Enable data persistence using PVC
    ## @param postgresql.primary.persistence.existingClaim Existing PVC to re-use
    ## @param postgresql.primary.persistence.storageClass Storage class of backing PV
    ## @param postgresql.primary.persistence.size PVC Storage Request for postgres volume
    ##
    persistence:
      enabled: true
      storageClass: ""
      existingClaim: ""
      size: 1Gi
