## Default values for metacat.
## This is a YAML-formatted file.
##
##     * * *  NOTE: SOME VALUES INCLUDE THE PLACEHOLDER "${RELEASE_NAME}", WHICH  * * *
##     * * *        MUST BE REPLACED BY THE ACTUAL RELEASE NAME                   * * *
##
## 1. Create a values-override file that overrides only the values you need to change (including
##    those containing the release name). This allows you to keep a versioned copy of your overrides
##    for each release. See examples in the metacat/helm/examples directory.
##
## 2. Install or upgrade using:
##      $ helm install --upgrade myrelease -n mynamespace-f myValues.yaml \
##                 oci://ghcr.io/nceas/charts/metacat --version [version]
##
##    ...assuming release name is "myrelease"; values-override filename is "myValues.yaml" and
##    namespace is "mynamespace". Charts and their version numbers can be found at:
##            https://github.com/NCEAS/metacat/pkgs/container/charts%2Fmetacat
##
## If you wish to deploy using a local copy of the helm chart (e.g. for development), then get a
## copy of the code from GitHub (https://github.com/NCEAS/metacat), and install or upgrade using:
##
## $ helm install --upgrade myrelease -n mynamespace-f myValues.yaml ./helm
##

## @section Global Properties Shared Across Sub-Charts Within This Deployment
##
global:
  ## @param global.metacatExternalBaseUrl Metacat base url accessible from outside cluster.
  ## Include protocol and trailing slash, but not the context; e.g.: "https://test.arcticdata.io/"
  ##
  metacatExternalBaseUrl: "https://localhost/"

  ## @param global.d1ClientCnUrl The url of the CN; used to populate metacat's 'D1Client.CN_URL'
  ## and the indexer sub-chart's 'D1Client.CN_URL'.
  ## (Also parsed by the MetacatUI sub-chart to retrieve the CN base URL)
  ##
  d1ClientCnUrl: "https://cn.dataone.org/cn"

  ## @param global.metacatAppContext The application context to use
  ## - for example, if your application is hosted at https://mydomain.org, and you define the
  ## context to be "metacat", then the application may be accessed at: https://mydomain.org/metacat/
  ## IMPORTANT NOTE: if changing this value, ensure the following paths are also updated to match:
  ##   readinessProbe.httpGet.path; livenessProbe.httpGet.path
  ##
  ## (Note the actual key metacatAppContext is used by the indexer sub-chart, and the anchor
  ##  &passwordSecretName is used elsewhere in this file. IF YOU OVERRIDE THIS VALUE IN ANOTHER
  ## VALUES-OVERLAY FILE, YOU ALSO NEED TO OVERRIDE THE VALUES THAT USE THIS ANCHOR - search this
  ## file for 'metacatAppContext')
  ##
  metacatAppContext: &metacatAppContext metacat

  ## @param global.storageClass default name of the storageClass to use for PVs
  ##
  ## Inspect your cluster to see what storageClass is set as default:
  ##    $  kubectl get storageclass
  ## ...and then explicitly set storageClass to match the name of the default storageclass
  ## (e.g. for Rancher Desktop, use:   storageclass: local-path)
  ##
  storageClass: local-path

  ## @param global.ephemeralVolumeStorageClass Optional global storageClass override
  ## Can be used to assign a storageClass that has a 'Delete' Reclaim Policy, thus allowing
  ## ephemeral volumes to be cleaned up automatically (eg "csi-cephfs-sc-ephemeral")
  ## Set ephemeralVolumeStorageClass: "" to use default StorageClass, if one is set on your cluster
  ##
  ephemeralVolumeStorageClass: ""

  ## @param global.sharedVolumeSubPath The subdirectory of the metacat data volume to mount
  ## Useful where one PV is used for multiple services, so each has its own subtree.
  ##
  ## (Note the actual key sharedVolumeSubPath is not used anywhere; only the yaml anchor/alias
  ##  &sharedVolumeSubPath. IF YOU OVERRIDE THIS VALUE IN ANOTHER VALUES-OVERLAY FILE, YOU ALSO
  ## NEED TO OVERRIDE THE VALUES THAT USE THIS ANCHOR - search this file for 'sharedVolumeSubPath')
  ##
  sharedVolumeSubPath: &sharedVolumeSubPath ""

  ## @param global.dataone-indexer.enabled Enable the dataone-indexer sub-chart
  ## set to false if you want to connect to your own existing dataone-indexer deployment
  ##
  dataone-indexer.enabled: true

  ## @param global.includeMetacatUi  Enable or disable the MetacatUI sub-chart.
  ## Set to false if you want to connect to your own existing MetacatUI deployment.
  ## See global.metacatUiIngressBackend (optional) if you wish to configure the ingress for your own
  ## existing MetacatUI k8s deployment in the same namespace.
  ##
  includeMetacatUi: true

  ## global.metacatUiIngressBackend - optional ingress backend for a non-subchart MetacatUI release.
  ## Will be added verbatim to the Ingress rules configuration, to allow metacat to work alongside a
  ## MetacatUI instance deployed IN THE SAME NAMESPACE [note 1], via a separate helm chart (i.e. not
  ## a subchart of this one).
  ## IMPORTANT: metacatUiIngressBackend will be IGNORED unless ALL the following conditions are met:
  ## 1. 'global.metacatUiIngressBackend.enabled' is set to 'true'
  ## 2. 'global.includeMetacatUi' is set to 'false' (i.e. MetacatUI is not deployed as a subchart)
  ## 3. 'ingress.enabled' is set to 'true'
  ## 4. 'ingress.rules' is empty [] (i.e. explicit ingress.rules will always take precedence)
  ##
  ## NOTE 1: If you are deploying MetacatUI in a different namespace than metacat, then you can use
  ##         an 'ExternalName' Service to act as a proxy. See:
  ##         https://stackoverflow.com/questions/59844622/ingress-configuration-for-k8s-in-different-namespaces
  ## NOTE 2: 'spec.rules.http.paths.path' will automatically be set to match any request with a
  ##         prefix  matching whatever is set as 'global.metacatUiWebRoot', so don't forget to
  ##         override that, if you want to use a different prefix than the default "/"
  ##
  metacatUiIngressBackend:
    ## @param global.metacatUiIngressBackend.enabled Enable or disable MetacatUI support via Ingress
    ##
    enabled: false
    service:
      ## @param global.metacatUiIngressBackend.service.name MetacatUI service name (ignored if 'global.includeMetacatUi: true')
      ## This should be overridden with the name of the service created by the MetacatUI chart.
      ##
      name: ${METACATUI_RELEASE_NAME}-metacatui
      port:
        ## @param global.metacatUiIngressBackend.service.port.number Port for MetacatUI service (used only if 'global.includeMetacatUi: false')
        ##
        number: 80

  ## @param global.metacatUiThemeName MetacatUI theme name to use. (used only if 'global.includeMetacatUi: true')
  ##
  metacatUiThemeName: "knb"

  ## @param global.metacatUiWebRoot The url root to be appended after the MetacatUI baseUrl.
  ## Starts with "/". Required, even if overriding config.js
  ##
  metacatUiWebRoot: "/"


## @section Metacat Application-Specific Properties
##
## The metacat section can contain any properties that metacat would expect to find in its
## configuration. These will be mounted in the container as metacat-site.properties,
## and will override the corresponding values in metacat.properties.
## The properties that have been pre-populated in this section comprise the minimum set of
## values needed to run the app and the test suite on a development machine.
##
## NOTE that certain credentials must also be provided, via Kubernetes Secrets, in order for
## metacat to function correctly. These credentials are listed in ./admin/secret--metacat.yaml, in the
## form of environment variables expected by metacat at runtime. Also see the mappings in the
## `application.envSecretKeys` property in `metacat.properties`, to determine which metacat
## property corresponds to each of these environment variables
##
metacat:
  ## @param metacat.application.context see global.metacatAppContext
  ##
  application.context: *metacatAppContext

  ## @param metacat.auth.administrators A semicolon-separated list of admin ORCID iDs
  ## (https://orcid.org), denoting the users who may log into metacat with administrator privileges.
  ## IMPORTANT NOTE: ORCID IDs *MUST* begin with http, *NOT* https! example:
  ## auth.administrators: http://orcid.org/0000-0002-1472-913X;http://orcid.org/0000-0002-1209-5268
  ##
  auth.administrators: ""

  ## @param metacat.database.connectionURI postgres database URI (or blank if using CloudNative PG)
  ## NOTE: If using a CloudNative PostgreSQL cluster, leave 'database.connectionURI' blank, and
  ## ensure that 'database.serviceName' is set instead (i.e. this value overrides
  ## 'database.serviceName')
  ##
  ## Format:    jdbc:postgresql://<postgres-hostname>/<database-name>
  ##
  ## ensure <database-name> is set correctly, and use the following values for <postgres-hostname>:
  ##  *  The fully qualified domain name, for an existing postgresql instance hosted outside the
  ##     current k8s cluster
  ##  *  `<servicename>.<namespace>.svc.cluster.local` for an existing postgresql instance within
  ##     the same k8s cluster
  ##  *  `host.docker.internal` for connecting to a dev instance running on localhost
  ##
  database.connectionURI: ""

  ## @param metacat.guid.doi.enabled Allow users to publish Digital Object Identifiers at doi.org?
  ## If true, you will also need to define guid.doi.username $ guid.doi.password (see secret--metacat.yaml)
  ## and either override or use the defaults in metacat.properties for all the entries that begin
  ## with: "guid.doi."
  ##
  guid.doi.enabled: true

  ## @param metacat.server.port The http port exposed externally, if NOT using the ingress
  ## to allow connections from outside the k8s cluster (e.g. if you're using a loadBalancer
  ## service or kubectl proxy instead). If not using the ingress, you will also need to specify a
  ## value for server.https: (either "true" or "false"), depending on whether you're using TLS.
  ##
  ## If you ARE using the ingress (i.e. `.Values.ingress.enabled` is `true`), then leave both
  ## 'server.port' and 'server.https' unset, and they will both be autopopulated, depending upon
  ## whether you have TLS set up for the ingress
  ##
  server.port: ""

  ## @param metacat.solr.baseURL The url to access solr, or leave blank to use sub-chart
  ##
  ## Format:    http://<solr-hostname>:<solr-port>/solr
  ##
  ## NOTES:
  ## 1. If you are NOT using the included "dataone-indexer" sub-chart (i.e.
  ##    `global.dataone-indexer.enabled: false`), ensure `<solr-port>` is set correctly, and use one
  ##    of the following values for `<solr-hostname>`:
  ##    *  The fully qualified domain name, for an existing solr instance hosted outside the
  ##       current k8s cluster
  ##    *  `<servicename>` for an existing postgresql instance within the same k8s cluster
  ##        e.g. "http://metacatbrooke-solr-headless:8983/solr"
  ##    *  `host.docker.internal` for connecting to a dev instance running on localhost
  ##        e.g. http://host.docker.internal:8983/solr
  ##
  ## 2. If you ARE using the included dataone-indexer sub-chart (i.e.
  ##    `global.dataone-indexer.enabled: true`), leave this value unset (`solr.baseURL: ""`). It
  ##    will then be automatically populated, as follows:
  ##    `<solr-hostname>` will be set to the current value of `.Release.Name`, prepended to
  ##                      `-solr-headless` (the name of the k8s headless solr service created
  ##                      by the dataone-indexer sub-chart)
  ##    `<solr-port>` will be set to 8983, the default value used by the dataone-indexer sub-chart
  ##
  solr.baseURL: ""    # leave blank to use sub-chart

  ## @param metacat.solr.coreName The solr core (solr standalone) or collection name (solr cloud)
  ## If you are using the included dataone-indexer sub-chart (i.e.
  ## `global.dataone-indexer.enabled: true`), leave this value unset (`solr.coreName: ""`). It will
  ## then be automatically populated from the subchart settings
  ##
  solr.coreName: ""    # leave blank to autopopulate from subchart settings

  ## @param metacat.replication.logdir Location for the replication logs
  ##
  replication.logdir: /var/metacat/logs

  ## @param metacat.index.rabbitmq.hostname the hostname of the rabbitmq instance that will be used
  ##
  index.rabbitmq.hostname: ""    # Leave blank to autopopulate with indexer sub-chart hostname

  ## @param metacat.index.rabbitmq.username the username for connecting to the RabbitMQ instance
  ## at `index.rabbitmq.hostname`.
  ##
  index.rabbitmq.username: &rmqUsername metacat-rmq-guest

  ## @section OPTIONAL DataONE Member Node (MN) Parameters
  ##

  ## @param metacat.cn.server.publiccert.filename optional cert(s) used to validate jwt auth tokens,
  ## in addition to attempting validation against the cert chain from the cn (see
  ## 'global.d1ClientCnUrl').
  ## It may contain a single cert path, or multiple paths, separated by semicolons.
  ## IMPORTANT NOTE: each file must contain only one public key. Certificate chains containing
  ## multiple public keys will not work!
  ##
  cn.server.publiccert.filename: /var/metacat/pubcerts/DataONEProdIntCA.pem

  ## @param metacat.dataone.certificate.fromHttpHeader.enabled Enable mutual auth with client certs
  ## Setting `true` REQUIRED for all DataONE MN functionality -- mutual authentication with x509
  ## client-side certs. Also see `ingress.d1CaCertSecretName`
  ##
  ## IMPORTANT NOTES
  ## 1. X509 client authentication forwarding using HTTP headers:
  ## Disables/enables the proxy forwarding of client X509 certificates and subjects from an upstream
  ## ingress. Do not enable this feature unless:
  ##    1. Your ingress performing SSL termination and your Metacat server are on the same trusted
  ##       cluster or trusted private network
  ##    2. The X509 client certificates have been verified by your upstream trusted ingress, and
  ##    3. The certificate information in the HTTP headers is set by the upstream trusted ingress.
  ## Using this feature in any other manner can result in security vulnerabilities.  It is only
  ## intended for use in containerized systems and their internal networks.
  ## Please do NOT enable it unless you understand what you are doing.
  ##
  ## 2. You will also need to set a shared secret between you trusted upstream ingress and Metacat -
  ##    see METACAT_DATAONE_CERT_FROM_HTTP_HEADER_PROXY_KEY in `./admin/secret--metacat.yaml`.
  ##    The ingress must be configured to send HTTP requests to Metacat with an "X-Proxy-Key" HTTP
  ##    header, with this shared secret as a value. See the `ingress` part of the `Networking &
  ##    Monitoring` section below.
  ##
  ## 3. You DO NOT need to configure the Member Node client cert location. Instead, simply add it as
  ##    a secret: https://github.com/NCEAS/metacat/tree/develop/helm#install-the-client-certificate
  ##
  dataone.certificate.fromHttpHeader.enabled: false

  ## @param metacat.dataone.autoRegisterMemberNode Automatically push MN updates to CN? (yyyy-MM-dd)
  ## USE WITH CARE!
  ## Metacat checks this value upon startup, and will attempt to push the current Member Node (MN)
  ## configuration (either new registration or updated settings - see below) to the configured
  ## Coordinating Node (CN), but ONLY if dataone.autoRegisterMemberNode MATCHES TODAY'S DATE (at
  ## metacat startup), IN UTC (Coordinated Universal Time) ZONE.
  ## Format: yyyy-MM-dd; e.g. 2023-02-28
  ##
  dataone.autoRegisterMemberNode: 2023-02-28

  ## metacat.D1Client.CN_URL the url of the CN - DO NOT SET HERE
  ## D1Client.CN_URL: This is set in the global value 'global.d1ClientCnUrl', above

  ## @param metacat.dataone.nodeId The unique ID of your DataONE MN - must match client cert subject
  ## The Node Identifier field is a unique identifier assigned by DataONE to identify this node even
  ## when the node changes physical locations over time. After Metacat registers with the DataONE
  ## Coordinating Nodes, the Node Identifier should not be changed. It is CRITICAL that you do NOT
  ## change the Node Identifier after registration, since that would break the connection with the
  ## DataONE network. Changing this field should only happen in the rare case in which a new
  ## Metacat instance is being established to act as the provider for an existing DataONE Member
  ## Node, in which case the field can be edited to set it to the value of a valid, existing Node
  ## Identifier.
  ##
  dataone.nodeId: urn:node:METACAT_TEST

  ## @param metacat.dataone.subject The "subject" string from your DataONE MN client certificate
  ## The Node Subject is critical for proper operation of the node. To act as a Member Node in
  ## DataONE, you must obtain an X.509 certificate that can be used to identify this node and allow
  ## it to securely communicate using SSL with other nodes and client applications. This
  ## certificate can be obtained from the DataONE Certificate Authority. Be sure to protect the
  ## certificate file, since it contains the private key that is used to authenticate this node
  ## within DataONE.
  ## Once you have the certificate in hand, use a tool such as openssl to determine the exact
  ## subject distinguished name in the certificate, and use that to set the Node Subject field.
  ## NOTE: The actual subject string in your certificate may be in the format:
  ##           Subject: DC = org, DC = dataone, CN = urn:node:YOUR_VALUE
  ##       ...but the dataone.subject parameter needs to have this reversed, have all whitespace
  ##       removed, and wrapped in double quotes, so it becomes:
  ##           dataone.subject: "CN=urn:node:YOUR_VALUE,DC=dataone,DC=org"
  ##
  dataone.subject: "CN=urn:node:METACAT1,DC=dataone,DC=org"

  ## @param metacat.dataone.nodeName short name for the node that can be used in user interfaces
  ## @param metacat.dataone.nodeDescription What is the node's intended scope and purpose?
  dataone.nodeName: My Metacat Node
  dataone.nodeDescription: Describe your Member Node briefly.

  ## @param metacat.dataone.contactSubject registered contact for this MN
  ## IMPORTANT NOTE: Before registering you MN, you will need to first register your contact subject
  ## identity in the DataONE production environment. First, if you don't already have one, create an
  ## ORCID (https://orcid.org/). Then use it to log in at https://search.dataone.org/signin, which
  ## will register you automatically. Then you can use your registered ORCID when you apply for
  ## an x509 client certificate, and use it as the value of dataone.contactSubject
  ## NOTE: you must use 'http://...' and NOT 'https://...' for this ORCID value:
  ##
  dataone.contactSubject: http://orcid.org/0000-0002-8888-999X

  ## @param metacat.dataone.nodeSynchronize Enable Synchronization of Metadata to DataONE
  ## Allows the administrator to decide whether to turn on synchronization with the DataONE
  ## network. When `false`, the DataONE Coordinating Nodes will not attempt to synchronize at all.
  ## When `true`, DataONE will periodically contact this node to synchronize all metadata content.
  ## To be part of the DataONE network, this must be set to `true`, since that allows DataONE to
  ## receive a copy of the metadata associated with each object in this Metacat system. The switch
  ## is provided for those rare cases when a node needs to be disconnected from DataONE for
  ## maintenance or service outages.
  ## (Default value shown - no need to uncomment unless changing from this)
  ##
  dataone.nodeSynchronize: false

  ## metacat.dataone.nodeSynchronization.schedule: DataONE synchronization schedule (crontab format)
  ##
  ## @param metacat.dataone.nodeSynchronization.schedule.year sync schedule year
  ## @param metacat.dataone.nodeSynchronization.schedule.mon sync schedule month
  ## @param metacat.dataone.nodeSynchronization.schedule.mday sync schedule day of month
  ## @param metacat.dataone.nodeSynchronization.schedule.wday sync schedule day of week
  ## @param metacat.dataone.nodeSynchronization.schedule.hour sync schedule hour
  ## @param metacat.dataone.nodeSynchronization.schedule.min sync schedule minute
  ## @param metacat.dataone.nodeSynchronization.schedule.sec sync schedule second
  ##
  ## When dataone.nodeSynchronize is set to `true`, DataONE contacts this node using the schedule
  ## provided in these Synchronization Schedule fields. The defaults below have synchronization
  ## occurring once every third minute at the 10-second mark of those minutes. The syntax for these
  ## schedules follows the Quartz Crontab Entry syntax, which provides for many flexible schedule
  ## configurations. Less frequent updates, such as daily, can be configured by changing the '*' in
  ## the 'Hours' field to be a concrete hour (such as 11) and the 'Minutes' field to a concrete
  ## value like '15', which would change the schedule to synchronize at 11:15 am daily.
  ## (Default values shown - no need to uncomment unless changing from these)
  ##
  dataone.nodeSynchronization.schedule.year: "*"
  dataone.nodeSynchronization.schedule.mon: "*"
  dataone.nodeSynchronization.schedule.mday: "*"
  dataone.nodeSynchronization.schedule.wday: "?"
  dataone.nodeSynchronization.schedule.hour: "*"
  dataone.nodeSynchronization.schedule.min: "0/3"
  dataone.nodeSynchronization.schedule.sec: "10"

  ## @param metacat.dataone.nodeReplicate Accept and Store Replicas?
  ## Used to indicate that the administrator of this node is willing to allow replica data and
  ## metadata from other Member Nodes to be stored on this node. We encourage people to allow
  ## replication to their nodes, thus increasing the scalability and flexibility of the network
  ## overall.
  ## (Default value shown - no need to uncomment unless changing from this)
  ##
  dataone.nodeReplicate: false

  ## @param metacat.dataone.replicationpolicy.default.numreplicas # copies to store on other nodes
  ## @param metacat.dataone.replicationpolicy.default.preferredNodeList Preferred replication nodes
  ## @param metacat.dataone.replicationpolicy.default.blockedNodeList Nodes blocked from replication
  ##
  ## The above three “Default” fields set the default values for the replication policies for data
  ## and metadata on this node that are generated when System Metadata is not available for an
  ## object (such as when it originates from a client that is not DataONE compliant).
  ##
  ## The Default Number of Replicas determines how many replica copies of the object should be
  ## stored on other Member Nodes. A value of 0 or less indicates that no replicas should be stored.
  ##
  ## In addition, you can specify a list of nodes that are either preferred for use when choosing
  ## replica nodes, or that are blocked from use as replica nodes. This allows Member Nodes to
  ## set up bidirectional agreements with partner nodes to replicate data across their sites. The
  ## values for both Default Preferred Nodes and Default Blocked Nodes is a comma-separated list
  ## of NodeReference identifiers that were assigned to the target nodes by DataONE.
  ##
  dataone.replicationpolicy.default.numreplicas: "0"
  dataone.replicationpolicy.default.preferredNodeList: ""
  dataone.replicationpolicy.default.blockedNodeList: ""

  ## @section OPTIONAL (but Recommended) Site Map Parameters
  ##

  ## @param metacat.sitemap.enabled Enable sitemaps to tell search engines which URLs are available
  ## for crawling (recommended - see https://knb.ecoinformatics.org/knb/docs/sitemaps.html)
  ##
  ## NOTE: If you are creating a non-production deployment, leave 'sitemap.enabled: false', and
  ## the chart will automatically create a robotx.txt file that prevents any search engine indexing
  ##
  ## When 'sitemap.enabled: true', Metacat automatically generates a sitemap index file, at:
  ##
  ##   <global.metacatExternalBaseUrl>/<application.context>/sitemaps/sitemap_index.xml
  ##
  ## ...and creates a robots.txt file that points to it (see .Values.robots).
  ##
  ## The index file contains a list of sitemap.xml files. Each listing is of the form:
  ##
  ##   <sitemap>
  ##     <loc>https://metacat.dataone.org/sitemap1.xml</loc>
  ##     <lastmod>2024-04-22</lastmod>
  ##   </sitemap>
  ##
  ## ...for 1 or more sitemap files, named sitemap1.xml, sitemap2.xml, etc. These sitemap files
  ## are also located at:
  ##
  ##   <global.metacatExternalBaseUrl>/<application.context>/sitemaps/sitemap1.xml ...etc.
  ##
  ## Each sitemap file contains up to 50,000 entries, each pointing to a dataset that is publicly
  ## readable metadata, is the newest version in a version chain, and has not been archived.
  ##
  ## URL entries are of the form:
  ##
  ##   <url>
  ##     <loc>https://metacat.dataone.org/view/some-identifier-here</loc>
  ##     <lastmod>2024-03-29</lastmod>
  ##   </url>
  ##
  sitemap.enabled: false

  ## @param metacat.sitemap.interval Interval (in milliseconds) between rebuilding the sitemap
  ## default (sitemap.interval: "86400000") is 24 hours.
  ##
  sitemap.interval: "86400000"

  ## @param metacat.sitemap.location.base The first part of the URLs listed in sitemap_index.xml
  ## Either full URL or absolute path. Trailing slash optional.
  ##
  ## sitemap_index.xml contains listings pointing to the sitemap(n).xml files. If we set:
  ##   sitemap.location.base: "/"
  ##   (or sitemap.location.base: "https://metacat.dataone.org/")
  ##
  ## ...then each listing will be of the form:
  ##   <sitemap>
  ##     <loc>https://metacat.dataone.org/sitemap1.xml</loc>
  ##     <lastmod>2024-04-22</lastmod>
  ##   </sitemap>
  ##
  ## NOTE: the actual files will always be stored in the <application.context>/sitemaps directory
  ## (e.g. https://knb.ecoinformatics.org/knb/sitemaps/sitemap1.xml), irrespective of the
  ## value you set for sitemap.location.base.
  ##
  sitemap.location.base: /

  ## @param metacat.sitemap.entry.base base URI of the dataset landing page, listed in the sitemap
  ## file(s) themselves.
  ## Either full URI or absolute path. Trailing slash optional.
  ##
  ## Each sitemap(n).xml file contains listings pointing to the individual datasets to be crawled.
  ## If we set:
  ## sitemap.entry.base: /view
  ##   (or sitemap.entry.base: "https://metacat.dataone.org/view")
  ##
  ## ...then each listing will be of the form:
  ##   <url>
  ##     <loc>https://metacat.dataone.org/view/some-identifier-here</loc>
  ##     <lastmod>2024-03-29</lastmod>
  ##   </url>
  ##
  sitemap.entry.base: /view

## @section robots.txt file (search engine indexing)
## Also see .Values.metacat.sitemap.*
robots:
  ## @param robots.userAgent "User-agent:" defined in robots.txt file. Defaults to "*" if not set
  ## NOTE: this value is ignored, unless 'metacat.sitemap.enabled: true'
  ##
  userAgent: ""

  ## @param robots.disallow the "Disallow:" value defined in robots.txt file.
  ## NOTE: this value is ignored, unless 'metacat.sitemap.enabled: true'
  ##
  ## If 'metacat.sitemap.enabled: false', then 'disallow' will always default to:
  ##     robots.disallow: /
  ##
  ## If left unset (i.e. disallow: "") and 'metacat.sitemap.enabled: true', then will default to:
  ##     robots.disallow: /<metacat.application.context>/d1/mn/v2/packages/
  ##
  disallow: ""


## @section Metacat Image, Container & Pod Parameters
##

image:
  ## @param image.repository Metacat image repository
  ##
  repository: ghcr.io/nceas/metacat

  ## @param image.pullPolicy Metacat image pull policy
  ##
  pullPolicy: IfNotPresent

  ## @param image.tag Overrides the image tag. Will default to the chart appVersion if set to ""
  ##
  tag: ""

  ## @param image.debug Specify if container debugging should be enabled (sets log level to "DEBUG")
  ## Set to true if you would like to see extra information in metacat/tomcat logs.
  ## * * WARNING - FOR TESTING ONLY! * * May result in secrets being printed to logs in plain text.
  ##
  debug: false

## @param imagePullSecrets [array] Optional list of references to secrets in the same namespace
## to use for pulling any of the images used by this chart
imagePullSecrets: []

## @param container.ports Optional list of additional container ports to expose within the cluster
## This section allows ports to be opened for development, debugging and testing purposes, in
## addition to the default metacat-web port 8080.
## Examples:
##     - containerPort: 5005
##       name: tc-remote-debug
##
## NOTE that port 8080 should not be included here - it is already defined in statefulset.yaml as:
##     - containerPort: 8080
##       name: metacat-web
##
container:
  ports: []

## ServiceAccount
## @param serviceAccount.create Should a service account be created to run Metacat?
## @param serviceAccount.annotations Annotations to add to the service account
## @param serviceAccount.name The name to use for the service account.
##                  If not set and create is true, a name is generated using the fullname template
##
serviceAccount:
  create: false
  annotations: {}
  name: ""

## @param podAnnotations Map of annotations to add to the pods
##
podAnnotations: {}

## PodSecurityContext - define common securityContext settings at the pod level for all containers
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
## @param podSecurityContext.enabled Enable security context
## @param podSecurityContext.runAsUser numerical User ID for the pod
## @param podSecurityContext.runAsGroup numerical Group ID for the pod
## @param podSecurityContext.fsGroup numerical Group ID used to access mounted volumes
## @param podSecurityContext.supplementalGroups [array] additional GIDs used to access vol. mounts
## @param podSecurityContext.runAsNonRoot ensure all containers run as a non-root user.
##                                 Note users must be defined by numerical user id for this to work
## @param podSecurityContext.fsGroupChangePolicy control how Kubernetes manages ownership & perms...
##                                IMPORTANT: use "OnRootMismatch" for large volumes! Using "Always"
##                                means K8s will always chown the volume to the fsGroup, even if the
##                                volume is already owned by the fsGroup, which is VERY slow!
## NOTE: If mounting an existing volume containing data, make sure the fsGroup is set to match
## the group that owns the existing data on that filesystem!
##
podSecurityContext:
  enabled: true
  runAsUser: 59997
  runAsGroup: 59997
  fsGroup: &mcFsGroup 59997
  supplementalGroups: &mcSupplementalGroups [ 997, 1000 ]
  runAsNonRoot: true
  fsGroupChangePolicy: &defaultFsGroupChangePolicy OnRootMismatch

## @param securityContext holds container-level security attributes that override those at pod level
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
securityContext: {}

## @param resources Resource limits for the deployment
## Resource requests and limits are left as a conscious choice for the user. This increases chances
## charts run on environments with limited resources, such as Minikube.
resources: {}

## @param tolerations Tolerations for pod assignment
tolerations: []

## @section Metacat Persistence
##
persistence:
  ## @param persistence.enabled Enable metacat data persistence using Persistent Volume Claims
  ## Always set to 'enabled: true' for production deployments.
  ##
  ## For development/testing ONLY: Setting 'enabled: false' will result in the use of a temporary
  ## 'emptyDir' for saving metacat's data. This means the data saved by metacat WILL BE LOST when
  ## the pod is deleted!
  ##
  enabled: true

  ## @param persistence.storageClass Override here or leave blank to use 'global.storageClass'
  ##
  storageClass: ""    # leave blank to use 'global.storageClass'

  ## @param persistence.existingClaim Name of an existing Persistent Volume Claim to re-use
  ## Set a value for 'existingClaim' only if you want to re-use a Persistent Volume Claim that has
  ## already been set up by a k8s admin ahead of time.
  ## Leaving it blank will cause a pvc to be created dynamically using volumeClaimTemplates.
  ##
  existingClaim: ""

  ## @param persistence.volumeName Name of an existing Volume to use for volumeClaimTemplate
  ## Set a value for 'volumeName' only if you want to re-use a Volume that has already been set up
  ## by a k8s admin ahead of time.
  ## Leaving it blank will cause a pvc to be created dynamically using volumeClaimTemplates.
  ##
  volumeName: ""

  ## @param persistence.subPath The subdirectory of the volume (see persistence.volumeName) to mount
  ## Useful where one PV is used for multiple services, so each has its own subtree.
  ##
  subPath: *sharedVolumeSubPath

  ## @param persistence.accessModes PVC Access Mode for metacat volume
  ## Metacat always requires read&write access, and dataone-indexer requires read access to the
  ## same PVC, so the ideal setup is:
  ##    accessModes:
  ##    - ReadWriteOnce   # allow only one node (i.e. metacat) to mount in read/write mode
  ##    - ReadOnlyMany    # allow many nodes (e.g. dataone-indexer, metadig) to mount read-only
  ##
  ## However, note that the underlying PersistentVolume (or pv auto-provisioner) must be able to
  ## provide these modes, in order for the PVC to bind successfully. Since neither NCEAS dev
  ## cluster nor Rancher Desktop supports RWO+ROX, we have to use RWX:
  ##   accessModes:
  ##     - ReadWriteMany
  ## ...and be careful to ensure that non-metacat services restrict themselves to RO access in their
  ## own PVC definitions
  ##
  accessModes:
    - ReadWriteMany

  ## @param persistence.size PVC Storage Request for metacat volume
  ##
  size: 1Gi

## @section Networking & Monitoring
##

## Ingress is a collection of rules that allow inbound connections to reach the endpoints defined
## by a backend. An Ingress can be configured to give services externally-reachable urls, load
## balance traffic, terminate SSL, offer name based virtual hosting etc.
##
ingress:
  ## @param ingress.enabled Enable or disable the ingress
  ##
  enabled: true

  ## @param ingress.className ClassName of the ingress provider in your cluster
  ##  Inspect available classes in your cluster using:    $ kubectl get ingressclasses
  ##
  ## className: "traefik" -- For Rancher Desktop (provided you have traefik enabled:
  ##     'preferences' -> 'kubernetes' -> 'enable traefik')
  ## className: "nginx" -- For production, or to use certificates locally. Also:
  ## - disable traefik ('preferences' -> 'kubernetes' -> uncheck 'enable traefik')
  ## - install nginx:
  ##   $  helm upgrade --install ingress-nginx ingress-nginx  \
  ##        --repo https://kubernetes.github.io/ingress-nginx \
  ##        --namespace ingress-nginx --create-namespace      \
  ##        --set controller.allowSnippetAnnotations=true
  ##
  className: "nginx"

  ## @param ingress.annotations [default: see values.yaml] `nginx.ingress.kubernetes.io` annotations
  ## These are mostly for enabling upload and download of large files and data packages, without
  ## timeouts or disconnects.
  ##
  ## NOTE: You do NOT need to do anything here for DataONE mutual authentication with x509
  ## client-side certs, provided:
  ## 1. you are using the Kubernetes open source community version of the nginx ingress
  ##    (see https://github.com/kubernetes/ingress-nginx)
  ## 2. you have set ingress.className to nginx, and
  ## 3. you have set up ingress.tls correctly for https access, and
  ## 4. you have set the correct parameters in the metacat section
  ##    (see `metacat.dataone.certificate.fromHttpHeader.enabled`, above, for more details)
  ##
  ## For other nginx annotation options, see:
  ## https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/
  ##
  annotations:
    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/client-body-buffer-size See docs:
    ## https://nginx.org/en/docs/http/ngx_http_core_module.html#client_body_buffer_size
    ##
    nginx.ingress.kubernetes.io/client-body-buffer-size: "1m"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/client_max_body_size See docs:
    ## https://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size
    ## Sets the maximum allowed size of the client request body. Setting to 0 disables checking of
    ## client request body size
    ##
    nginx.ingress.kubernetes.io/client_max_body_size: "0"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/send-timeout See docs:
    ## https://nginx.org/en/docs/http/ngx_http_core_module.html#send_timeout
    ## Sets a timeout for transmitting a response to the client. The timeout is set only between
    ## two successive write operations, not for the transmission of the whole response. If the
    ## client does not receive anything within this time, the connection is closed. Default is 60s,
    ## but we set it to 3600 seconds to prevent 504 Gateway Time-out when downloading zip files of
    ## huge datasets using bagit
    ##
    nginx.ingress.kubernetes.io/send-timeout: "3600"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/proxy-body-size See docs:
    ## https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/nginx-configuration/configmap.md#proxy-body-size
    ## Sets the maximum allowed size of the client request body - similar to the nginx
    ## client_max_body_size directive. Setting to 0 disables checking of client request body size
    ##
    nginx.ingress.kubernetes.io/proxy-body-size: "0"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/proxy-read-timeout See docs:
    ## https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout
    ## default is 60 seconds, but we set it to 3600 seconds to prevent 504 Gateway Time-out when
    ## downloading zip files of huge datasets using bagit
    ##
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/proxy-send-timeout See docs:
    ## https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_send_timeout
    ## The timeout is set only between two successive write operations, not for the transmission of
    ## the whole request. We set it to 3600 seconds to prevent 504 Gateway Time-out when
    ## downloading zip files of huge datasets using bagit
    ##
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/proxy-request-buffering See docs:
    ## https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_request_buffering
    ##
    nginx.ingress.kubernetes.io/proxy-request-buffering: "off"

    ## @skip ingress.annotations.nginx.ingress.kubernetes.io/proxy-buffering See docs:
    ## https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffering
    ## According to ingress-nginx docs, default is "off", but according to nginx docs, default is
    ## "on", so we set it explicitly to "off", be sure
    ##
    nginx.ingress.kubernetes.io/proxy-buffering: "off"

  ## @param ingress.defaultBackend.enabled enable the optional defaultBackend
  ## ingress.defaultBackend (optional) default for any requests not matching defined paths
  ## @param ingress.defaultBackend.enabled enable the optional defaultBackend
  ## If none of the hosts or paths match the HTTP request in the Ingress objects, the traffic is
  ## routed to your default backend. Not typically required, unless MetacatUI
  ## Content included here under `defaultBackend` will be added to the ingress definition under
  ## 'spec.defaultBackend'; for example:
  ##
  ##   spec:
  ##     defaultBackend:
  ##       enabled: true
  ##       service:
  ##         name: myrelease-wordpress
  ##         port:
  ##           number: 80
  ##
  defaultBackend:
    enabled: false

  ## @param ingress.rewriteRules formatted text rewrite rules for the nginx ingress
  ## These rules will be added to the ingress definition section:
  ## metadata:
  ##   annotations:
  ##     nginx.ingress.kubernetes.io/configuration-snippet: |
  ##       (* * *  list of rewrite rules here  * * *)
  ##
  ## Example syntax:
  ##     rewriteRules: |
  ##       if ($host = "evos.nceas.ucsb.edu") {
  ##           return 301 https://goa.nceas.ucsb.edu$request_uri;
  ##       }
  ##       rewrite ^/(sitemap.+) /metacat/sitemaps/$1 redirect;
  ##       rewrite ^/robots.txt /metacat/robots.txt redirect;
  ##
  ## (For example only; note the last two rules are already automatically included as needed - see
  ## .Values.robots.* and .Values.metacat.sitemap.*)
  ##
  rewriteRules: ""

  ## @param ingress.configurationSnippet [default: see values.yaml] added to nginx ingress config...
  ## This block will be added to the ingress definition section, in addition to the rewrite rules:
  ## metadata:
  ##   annotations:
  ##     nginx.ingress.kubernetes.io/configuration-snippet: |
  ##       (* * *  nginx.conf code block here  * * *)
  ##
  ## Note that overriding this block will disable the default cors setup, unless
  ## you copy this into your override
  ##
  configurationSnippet: |
    # Metacat Cors Setup

    set $cors 'true';

    if ($request_method = 'OPTIONS') {
      set $cors ${cors}options;
    }

    if ($cors = "true") {
      more_set_headers 'Access-Control-Allow-Origin: $http_origin';
      more_set_headers 'Access-Control-Allow-Credentials: true';
      more_set_headers 'Access-Control-Allow-Methods: POST, PUT, GET, OPTIONS';
      more_set_headers 'Access-Control-Allow-Headers: DNT,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization';

      more_set_headers 'Access-Control-Max-Age: 1728000';
    }

    if ($cors = "trueoptions") {
      more_set_headers 'Access-Control-Allow-Origin: $http_origin';
      more_set_headers 'Access-Control-Allow-Credentials: true';
      more_set_headers 'Access-Control-Allow-Methods: POST, PUT, GET, OPTIONS';
      more_set_headers 'Access-Control-Allow-Headers: DNT,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization';

      more_set_headers 'Access-Control-Max-Age: 1728000';
      more_set_headers 'Content-Type: text/plain charset=UTF-8';
      more_set_headers 'Content-Length: 0';
      return 204;
    }

  ## @param ingress.tls The TLS configuration
  ##
  ## Example:
  ##  tls:
  ##    - hosts:
  ##        - arcticdata.io
  ##        - www.arcticdata.io
  ##        - permafrost.arcticdata.io
  ##      secretName: ingress-nginx-tls-cert
  ##
  ## To disable TLS altogether (i.e. use http only), set:
  ##    tls: []
  ##
  ## To have tls.hosts auto-populated with external hostname (from global.metacatExternalBaseUrl),
  ## set only the secretName (always required), and leave hosts as an empty list - i.e:
  ##
  ##    tls:
  #       - hosts: []
  #         secretName: tls-secret-values-yaml
  ##
  tls: []

  ## @param ingress.rules The Ingress rules can be defined here or left blank to be auto-populated
  ## based on the global.metacatExternalBaseUrl value. If defining rules here, they will be copied
  ## verbatim to the ingress definition, overriding any automatic configuration in the template.
  ## For schema guidance, see:
  ## https://kubernetes.io/docs/concepts/services-networking/ingress/
  ## Example:
  ##    - host: knb.ecoinformatics.org
  ##      http:
  ##        paths:
  ##          - backend:
  ##              service:
  ##                name: metacatknb-hl
  ##                port:
  ##                  number: 8080
  ##            path: /knb
  ##            pathType: Prefix
  ##          - backend:
  ##              service:
  ##                name: metacatknb-metacatui
  ##                port:
  ##                  number: 80
  ##            path: /
  ##            pathType: Prefix
  ##
  rules: []

  ## @param ingress.d1CaCertSecretName Name of Secret containing DataONE CA certificate chain
  ## For DataONE Replication -- mutual authentication with x509 client-side certs.
  ## Also see `metacat.dataone.certificate.fromHttpHeader.enabled`
  d1CaCertSecretName: d1-ca-chain

## Optional service in addition to the Headless ClusterIP that is required for StatefulSet
service:
  ## @param service.enabled Enable another optional service in addition to headless svc
  enabled: false

  ## @param service.type Kubernetes Service type. Defaults to ClusterIP if not set
  type: LoadBalancer

  ## @param service.clusterIP IP address of the service. Auto-generated if not set
  ## Valid values are "None", empty string (""), or a valid IP address. Setting this to "None"
  ## makes a "headless service" (no virtual IP). Using empty string ("") will auto-generate an IP
  ##
  clusterIP: ""

  ## @param service.ports [array] The port(s) to be exposed
  ##        service.ports.port The port to expose
  ##        service.ports.name A unique name to identify this port.
  ##        service.ports.targetPort the name (preferred) or number of the container
  ##                                 port where traffic will be sent.
  ##
  ports:
    - name: http-port
      port: 8080
      targetPort: metacat-web

## Startup Probe
## Liveness and readiness probes are disabled until the startupProbe passes.
## If the startupProbe fails more than 'failureThreshold' times, the container is restarted.ß
## @param startupProbe.enabled Enable startupProbe for the Metacat container
## @param startupProbe.httpGet.path The url path to probe during startup
##                Note that the context (first path element) must match the
##                value of metacat.application.context
## @param startupProbe.httpGet.port The named containerPort to probe
##
startupProbe:
  enabled: true
  httpGet:
    path: /metacat/d1/mn/v2/monitor/ping
    port: metacat-web
  ## Optional values:
  ## @param startupProbe.successThreshold Min consecutive successes for probe to be successful
  ## @param startupProbe.failureThreshold No. of consecutive failures before the container restarted
  ## @param startupProbe.periodSeconds Interval (in seconds) between startup checks
  ## @param startupProbe.timeoutSeconds Timeout (in seconds) for each startup check
  successThreshold: 1
  failureThreshold: 30
  periodSeconds: 10
  timeoutSeconds: 5

## @param livenessProbe.enabled Enable livenessProbe for Metacat container
## We do not use a livenessProbe for Metacat, since it typically can have a lot of latency when
## overloaded, but recovers elegantly. (Setting a livenessProbe would mean the container would be
## restarted when the probe fails.)
##
livenessProbe:
  enabled: false

## Readiness Probe
## Periodic probe of container service readiness. If the probe fails, container will be removed
## from service endpoints (but will not be restarted unless livenessProbe fails)
##
## @param readinessProbe.enabled Enable readinessProbe for Metacat container
## @param readinessProbe.httpGet.path The url path to probe.
##                Note that the context (first path element) must match the
##                value of metacat.application.context
## @param readinessProbe.httpGet.port The named containerPort to probe
## Optional values:
## @param readinessProbe.periodSeconds Period seconds for readinessProbe
## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
## @param readinessProbe.successThreshold Min consecutive successes for probe to be successful
## @param readinessProbe.failureThreshold No. consecutive failures before container marked unhealthy
##
readinessProbe:
  enabled: true
  periodSeconds: 15
  timeoutSeconds: 10
  successThreshold: 1
  failureThreshold: 6
  httpGet:
    path: /metacat/d1/mn/v2/monitor/ping
    port: metacat-web

## @section PostgreSQL Database Connection Parameters
##
## Metacat requires a pre-existing PostgreSQL database, that has already been provisioned outside
## the Metacat Helm Chart's lifecycle.
## We recommend using the CloudNative PG Operator (https://cloudnative-pg.io/), although any
## suitable PostgreSQL database may be used (deployed either within or outside your Kubernetes
## cluster).
##
database:
  ## @param database.existingSecret REQUIRED Name of Secret holding the database username & password
  ## IMPORTANT:
  ##    - the secret must be of type 'kubernetes.io/basic-auth'
  ##    - the Secret must contain the exact key names: 'username' and 'password'
  ##    - the username must match the 'database.dbUser' value below
  ##
  ## Examples:
  ## 1. If using a secret created with the SAME release name as metacat:
  ##      database:
  ##        existingSecret: "{{ .Release.Name }}-cnpg-app"
  ##
  ##    (NOTE that the value may include Go templating to represent the release name, provided the
  ##    entire string is in quotes)
  ##
  ## 2. If using a secret auto-created by cnpg, with a release name DIFFERENT from metacat's:
  ##      database:
  ##        existingSecret: "mycnpgreleasename-cnpg-app"
  ##
  existingSecret: ""

  ## @param database.dbName The name of the PostgreSQL database to connect to
  ##
  dbName: metacat

  ## @param database.serviceName (REQUIRED if DB on k8s) name of the Service exposing the database
  ## Ignored if using an external database (i.e. outside the k8s cluster), in which case the value
  ## 'metacat.database.connectionURI' must be set.
  ##
  ## Example:
  ##   serviceName: mycnpgreleasename-cnpg-rw
  ##
  serviceName: ""

  ## @param database.port Override default database port (5432) - only if not using CNPG
  ## Otherwise leave as 5432, since this is the default for CNPG
  ##
  port: 5432

## @section Tomcat Configuration
tomcat:
  ## @param tomcat.jmxEnabled Enable JMX for Tomcat, to inspect JVM usage of CPU, memory, etc.
  ## When JMX is enabled by setting this to 'true', you can view the JMX metrics using a JMX client
  ## such as VisualVM or JConsole, connected via port-forwarding to the port set in tomcat.jmxPort
  ##
  jmxEnabled: false

  ## @param tomcat.jmxPort The port to use for JMX connections. IMPORTANT: If you change this...
  ## 1. you must also change the port in the tomcat.jmxCatalinaOpts section, in the following two
  ##    entries:
  ##     -Dcom.sun.management.jmxremote.port=9010
  ##     -Dcom.sun.management.jmxremote.rmi.port=9010
  ##
  ## 2. If you plan on using a different port # on localhost, it's easiest to use that same port on
  ##    the pod, so you're using a single port for both JMX and RMI.(e.g. instead of port
  ##    forwarding from pod:9010 to localhost:9011, expose jmx on pod:9011 and forward from pod:9011
  ##    to localhost:9011)
  ##
  ## Note that the JMX port is not (and should not be) exposed outside the cluster. It is therefore
  ## necessary to use port-forwarding in order to connect.
  ##
  jmxPort: 9010

  ## @param tomcat.jmxCatalinaOpts [default: see values.yaml] Tomcat JVM options for enabling JMX
  ## Use these to change the port, for example, or to enable authentication.
  ##
  ## IMPORTANT NOTES:
  ## 1. If you change the port numbers here, you must also change the value of tomcat.jmxPort to
  ##    match!
  ## 2. If you plan on using a different port # on localhost, it's easiest to use that same port on
  ##    the pod, so you're using a single port for both JMX and RMI.(e.g. instead of port
  ##    forwarding from pod:9010 to localhost:9011, expose jmx on pod:9011 and forward from pod:9011
  ##    to localhost:9011)
  ##
  ## (jmxCatalinaOpts is a yaml list, so each entry must be preceded by a dash (-) and a space. It
  ## looks strange when the options also contain dashes, but is correct YAML syntax.)
  ##
  jmxCatalinaOpts:
    - -Dcom.sun.management.jmxremote
    - -Dcom.sun.management.jmxremote.port=9010
    - -Dcom.sun.management.jmxremote.rmi.port=9010
    - -Dcom.sun.management.jmxremote.local.only=false
    - -Dcom.sun.management.jmxremote.authenticate=false
    - -Dcom.sun.management.jmxremote.ssl=false
    - -Djava.rmi.server.hostname=127.0.0.1

  ## @param tomcat.heapMemory.min minimum memory heap size for Tomcat (-Xms JVM parameter)
  ## @param tomcat.heapMemory.max maximum memory heap size for Tomcat (-Xmx JVM parameter)
  ## Typical values: Prod - min 8G, max 16G; Test - min 2G, max 4G; dev - can leave unset
  ##
  ## IMPORTANT NOTE
  ## ALWAYS configure Java’s maximum heap size (-Xmx, set by tomcat.heapMemory.max) to be LOWER THAN
  ## the memory limit set in Kubernetes. If you set a memory limit in Kubernetes, and Java exceeds
  ## that, your container will be killed. A safer method is to NOT set -Xmx, and instead rely upon
  ## setting -XX:MaxRAMPercentage in extraCatalinaOpts, below.
  ##
  heapMemory:
    min: ""
    max: ""

  ## @param tomcat.extraCatalinaOpts Extra JVM options to pass to Tomcat. SEE IMPORTANT NOTES BELOW:
  ## 1. Do not pass -Xms or -Xmx here. Those values should be passed separately, using the values:
  ##    tomcat.heapMemory.min and tomcat.heapMemory.max
  ## 2. Do not set JMX-related values here, without first checking they're not already defined in
  ##    tomcat.jmxCatalinaOpts (assuming tomcat.jmxEnabled is true)
  ## 3. -XX:MaxRAMPercentage may be set here, but note that it will be ignored by the JVM if you
  ##    also set a value for -Xmx (i.e. -Xmx takes precedence over MaxRAMPercentage)
  ##
  ## (extraCatalinaOpts is a yaml list, so each entry must be preceded by a dash (-) and a space. It
  ## looks strange when the options also contain dashes, but is correct YAML syntax.)
  ##
  extraCatalinaOpts:
    - -XX:MaxRAMPercentage=75

## @section dataone-indexer Sub-Chart
##
## Metacat depends upon the dataone-indexer subchart (i.e. 'global.dataone-indexer.enabled' is set
## to 'true' by default). If you set 'global.dataone-indexer.enabled: false', the settings in this
## section are ignored
##
dataone-indexer:

  ## dataone-indexer.PodSecurityContext - define common securityContext settings at the pod
  ## level for all containers
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  ## @param dataone-indexer.podSecurityContext.fsGroup gid used to access mounted volumes
  ## @param dataone-indexer.podSecurityContext.supplementalGroups [array] additional vol access gids
  ## @param dataone-indexer.podSecurityContext.fsGroupChangePolicy ownership & perms mgmt
  ##                        IMPORTANT: use "OnRootMismatch" for large volumes! Using "Always"
  ##                        means K8s will always chown the volume to the fsGroup, even if the
  ##                        volume is already owned by the fsGroup, which is VERY slow!
  podSecurityContext:
    fsGroup: *mcFsGroup
    supplementalGroups: *mcSupplementalGroups
    fsGroupChangePolicy: *defaultFsGroupChangePolicy

  persistence:
    ## @param dataone-indexer.persistence.subPath The subdirectory of the volume to mount
    ## (see persistence.volumeName)
    ## Useful where one PV is used for multiple services, so each has its own subtree.
    ##
    subPath: *sharedVolumeSubPath

  idxworker:
    ## @skip dataone-indexer.idxworker.resourcemapMaxTries resource map indexing max attempts
    ## temp fix for resourcemaps not getting indexed
    ## keep default for: resourcemapWaitMs: 800
    ## increase number of tries from 25 to:
    resourcemapMaxTries: 200

  rabbitmq:
    ## @param dataone-indexer.rabbitmq.extraConfiguration extra config, to be appended to rmq config
    ## Default consumer_timeout is 30 mins (i.e. 18000000mS). Increase this to 1hr to avoid timeouts
    ## with large resource maps
    ##
    ## 144000000 = 4 hours
    ##
    extraConfiguration: |-
      consumer_timeout = 144000000

    auth:
      ## @param dataone-indexer.rabbitmq.auth.username set the username that rabbitmq will use
      ##
      username: *rmqUsername

      ## @param dataone-indexer.rabbitmq.auth.existingPasswordSecret location of rabbitmq password
      ## This is usually the secret deployed using your own private, edited version of
      ## '../admin/secret--metacat.yaml'.
      ##
      ## IMPORTANT:
      ## - The Secret must contain the exact key name: 'rabbitmq-password'
      ## - Make sure you edit this, to replace ${RELEASE_NAME} with yours! For example, if
      ##   the release name is 'myrelease':
      ##   existingPasswordSecret: myrelease-metacat-secrets
      ##
      existingPasswordSecret: ${RELEASE_NAME}-metacat-secrets

  solr:
    ## @param dataone-indexer.solr.javaMem Java memory options to pass to the Solr container
    ##
    javaMem: "-Xms512m -Xmx2g"

    ## @param dataone-indexer.solr.customCollection name of the solr collection to use
    ## (optional override of indexer-assigned name). Do not leave blank!
    ## NOTE: if you change this value after having run metacat for the first time, you may need
    ## to delete and re-create the PVCs and PVs used by solr, in order for the new settings to
    ## become effective
    ##
    customCollection: metacat-index

    ## @param dataone-indexer.solr.coreNames Solr core names to be created
    ## (optional override of indexer-assigned names)
    ## NOTE: if you change this value after having run metacat for the first time, you may need
    ## to delete and re-create the PVCs and PVs used by solr, in order for the new settings to
    ## become effective
    ##
    coreNames:
      - metacat-core

    ## @param dataone-indexer.solr.persistence.size solr Persistent Volume size
    ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      size: 100Gi

    extraVolumes:
      ## @param dataone-indexer.solr.extraVolumes[0].name DO NOT EDIT - referenced by sub-chart
      - name: solr-config
        configMap:
          ## @param dataone-indexer.solr.extraVolumes[0].configMap.name see notes in values.yaml
          ## This is the name of the configMap created by the dataone-indexer. It has to be here
          ## because it is passed directly to the dataone-indexer subchart's own solr subchart via
          ## .Values, so cannot be set automatically. Unfortunate but true.
          ##
          ## IMPORTANT:
          ## - Make sure you edit this, to replace ${RELEASE_NAME} with yours! For example, if
          ##   the release name is 'myrelease':
          ##     name: myrelease-indexer-configfiles
          ##
          name: ${RELEASE_NAME}-indexer-configfiles
          ## @param dataone-indexer.solr.extraVolumes[0].configMap.defaultMode DO NOT EDIT
          defaultMode: 0777


    ## @param dataone-indexer.solr.zookeeper.persistence.size Persistent Volume size
    ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    zookeeper:
      persistence:
        size: 100Gi
